{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dO0lBwHKSsR"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/MyDrive/VKR/'\n",
        "path_in=path+'input/'\n",
        "path_out=path+'output/'\n",
        "path_tmp='/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn-2vKG1vVNG"
      },
      "outputs": [],
      "source": [
        "!pip install -U pyflagser\n",
        "!pip install pympler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaIt0r5yJeN-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy, scipy.stats\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pyflagser\n",
        "import json\n",
        "from sklearn.cluster import KMeans\n",
        "from pympler import asizeof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qNH0rp9ZSE4"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU9HaX5qnZEF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnR0Wdz4Lzsv"
      },
      "source": [
        "## Read graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DJnrPlZBmkN"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"rus_main.graphml\")\n",
        "name='rus/'\n",
        "G.number_of_edges(), G.number_of_nodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa80ZeYy6P41"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"en_r1_main.graphml\")\n",
        "name='en_r1/'\n",
        "G.number_of_edges(), G.number_of_nodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g62450Iq6Pqr"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"en_r123_main.graphml\")\n",
        "name='en_r123/'\n",
        "G.number_of_edges(), G.number_of_nodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cciRInkJaeMZ"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"dutch_main.graphml\")\n",
        "name='dutch/'\n",
        "G.number_of_edges(), G.number_of_nodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeVczZwQ6PLa"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"USF_main.graphml\")\n",
        "name='USF/'\n",
        "G.number_of_edges(), G.number_of_nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efVugMYvXYhH"
      },
      "source": [
        "## defs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPomcVNZu-U-"
      },
      "outputs": [],
      "source": [
        "def mle_power_law_params(degree_sequence): #find params of power law distribution of degree\n",
        "    x_min = max(np.floor(np.min(degree_sequence)), 1)\n",
        "    alpha = alpha_lin_bins(degree_sequence[degree_sequence>=x_min], 1000)\n",
        "    D, _ = scipy.stats.kstest(rvs=degree_sequence[degree_sequence>=x_min], cdf=power_law_cdf, args = (alpha, x_min))\n",
        "    for i in range(int(max(np.floor(np.min(degree_sequence)), 1))+1, int(np.floor(np.max(degree_sequence)))+1):\n",
        "        alpha_i = alpha_lin_bins(degree_sequence[degree_sequence>=i], 1000)\n",
        "        D_i, _ = scipy.stats.kstest(rvs=degree_sequence[degree_sequence>=i], cdf=power_law_cdf, args = (alpha_i, i))\n",
        "        if D_i < D:\n",
        "            D = D_i\n",
        "            x_min = i\n",
        "            alpha = alpha_i\n",
        "    return (alpha, x_min)\n",
        "\n",
        "def power_law_cdf(x, alpha=3.5, x_min=1):\n",
        "    f = np.maximum(1 - x ** (-alpha+1) / x_min ** (1 - alpha), 0)\n",
        "    return f\n",
        "\n",
        "def power_law_pdf(x, alpha=3.5, x_min=1):\n",
        "    C = (alpha - 1) / x_min ** (1 - alpha)\n",
        "    return C * x ** (-alpha)\n",
        "\n",
        "def alpha_lin_bins(x_train, bins):\n",
        "    hist, bin_edges = np.histogram(x_train, bins=bins, density=True)\n",
        "    bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
        "    log_x=np.log(bin_centers[hist > 0]).reshape(-1, 1)\n",
        "    e_cdf=np.log(hist[hist > 0]).reshape(-1, 1)\n",
        "    lin_reg = LinearRegression(fit_intercept=False)\n",
        "    lin_reg.fit(log_x, e_cdf)\n",
        "    return -lin_reg.coef_[0][0]\n",
        "\n",
        "def labels_list_parameters1(graph, layout, ct, scale=10, maxc=0, name=False, cut=True): #function for making labels size dependent on centrality\n",
        "    list_of_params = []\n",
        "    vals=ct.values() if isinstance(ct, dict) else ct\n",
        "    for c in set(vals):\n",
        "        params = {}\n",
        "        params['G'] = graph\n",
        "        params['pos'] = layout\n",
        "        params['labels'] = {}\n",
        "        params['font_size'] = c*scale+16 if c>=maxc else 6\n",
        "        for node in graph.nodes:\n",
        "            # print(ct[node])\n",
        "            if ct[node] == c:\n",
        "                params['labels'][node] = graph.nodes()[node]['name'] if name else str(node)\n",
        "                if c<maxc and cut:\n",
        "                    params['labels'][node] =' '\n",
        "        list_of_params.append(params)\n",
        "    return list_of_params\n",
        "\n",
        "def calculate_graph_features(G, save_to, csv=False, num=0, diam=True): #common graph features: see prints and titles for info\n",
        "  print(\"Number of nodes:\", G.number_of_nodes())\n",
        "  print(\"Number of edges:\", G.number_of_edges())\n",
        "  if nx.is_strongly_connected(G) and diam:\n",
        "    d=nx.diameter(G)\n",
        "    r=nx.radius(G)\n",
        "    a=round(nx.average_shortest_path_length(G), 4)\n",
        "    print(\"Diameter:\", d)\n",
        "    print(\"Radius:\", r)\n",
        "    print(\"ASPL:\", round(a))\n",
        "  elif diam:\n",
        "    print(\"Graph not strongly connected, diam et al for max SCC\")\n",
        "    sub=G.subgraph(max(nx.strongly_connected_components(G), key=len))\n",
        "    d=nx.diameter(sub)\n",
        "    r=nx.radius(sub)\n",
        "    a=round(nx.average_shortest_path_length(sub), 4)\n",
        "    print(\"Diameter:\", d)\n",
        "    print(\"Radius:\", r)\n",
        "    print(\"ASPL:\", round(a))\n",
        "  else:\n",
        "    print(\"Graph not strongly connected and parameter diam=False, skipping diam, etc.\")\n",
        "    d=np.inf\n",
        "    r=np.inf\n",
        "    a=np.inf\n",
        "  print('Transitivity:', round(nx.transitivity(G), 4))\n",
        "  print('ACC:', round(nx.average_clustering(G), 4))\n",
        "  print('Clique number:', nx.graph_clique_number(G.to_undirected()))\n",
        "  print('Density:', round(nx.density(G), 4))\n",
        "  print('Average node degree: {0:.2f}'.format(np.array(list(dict(G.degree()).values())).mean()))\n",
        "  print('Node degree variance: {0:.2f}'.format(np.array(list(dict(G.degree()).values())).var()))\n",
        "  print('Average node in-degree: {0:.2f}'.format(np.array(list(dict(G.in_degree()).values())).mean()))\n",
        "  print('Node in-degree variance: {0:.2f}'.format(np.array(list(dict(G.in_degree()).values())).var()))\n",
        "  print('Average node out-degree: {0:.2f}'.format(np.array(list(dict(G.out_degree()).values())).mean()))\n",
        "  print('Node out-degree variance: {0:.2f}'.format(np.array(list(dict(G.out_degree()).values())).var()))\n",
        "\n",
        "  if isinstance(csv, pd.DataFrame):\n",
        "    csv.loc[num]=[G.number_of_nodes(), G.number_of_edges(), d, r, a, \n",
        "                  round(nx.transitivity(G), 4), round(nx.average_clustering(G), 4), nx.graph_clique_number(G.to_undirected()),\n",
        "                  round(nx.density(G), 4), np.array(list(dict(G.degree()).values())).mean(), \n",
        "                  np.array(list(dict(G.degree()).values())).var(), np.array(list(dict(G.in_degree()).values())).mean(),\n",
        "                  np.array(list(dict(G.in_degree()).values())).var(), np.array(list(dict(G.out_degree()).values())).mean(),\n",
        "                  np.array(list(dict(G.out_degree()).values())).var(), 0, 0, 0, 0, 0, 0, \"\", \"\", \"\", \"\",\"\", \"\",\"\", \"\",\"\", \"\"]\n",
        "\n",
        "  d=(np.array(nx.degree_histogram(G))/G.number_of_nodes())\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  plt.figure(figsize=(8, 6), dpi=200)\n",
        "  plt.title(\"Degree distribution\")\n",
        "  plt.xlabel(\"Node degree\")\n",
        "  plt.ylabel(\"Fraction of degree\")\n",
        "  plt.bar(range(len(d)), d);\n",
        "  plt.savefig(save_to+'degree_gen.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  ind=np.array(list(dict(G.in_degree()).values()))\n",
        "  h=Counter(ind)\n",
        "  h=dict(h)\n",
        "  for i in range(max(ind)):\n",
        "    if not i in h:\n",
        "      h[i]=0\n",
        "  h=dict(sorted(h.items()))\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  plt.figure(figsize=(8, 6), dpi=200)\n",
        "  plt.title(\"In-degree distribution\")\n",
        "  plt.xlabel(\"Node in-degree\")\n",
        "  plt.ylabel(\"Fraction of degree\")\n",
        "  plt.bar(list(h.keys())[:1000], np.array(list(h.values())[:1000])/G.number_of_nodes());\n",
        "  plt.savefig(save_to+'degree_in.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  outd=np.array(list(dict(G.out_degree()).values()))\n",
        "  h=Counter(outd)\n",
        "  h=dict(h)\n",
        "  for i in range(max(outd)):\n",
        "    if not i in h:\n",
        "      h[i]=0\n",
        "  h=dict(sorted(h.items()))\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  plt.figure(figsize=(8, 6), dpi=200)\n",
        "  plt.title(\"Out-degree distribution\")\n",
        "  plt.xlabel(\"Node out-degree\")\n",
        "  plt.ylabel(\"Fraction of degree\")\n",
        "  plt.bar(list(h.keys())[:1000], np.array(list(h.values())[:1000])/G.number_of_nodes());\n",
        "  plt.savefig(save_to+'degree_out.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  \n",
        "\n",
        "  hist, bin_edges = np.histogram(ind, bins=1000, density=True)\n",
        "  bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  plt.figure(figsize=(8, 6), dpi=200)\n",
        "  plt.scatter(bin_centers[hist > 0], hist[hist > 0], s=5, label=\"Real PDF\")\n",
        "  plt.title('In-degree distribution')\n",
        "  hat_alpha, hat_x_min = mle_power_law_params(ind)\n",
        "  x_space = np.linspace(hat_x_min, ind.max(), 100)\n",
        "  plt.plot(x_space, power_law_pdf(x_space, hat_alpha, hat_x_min), \n",
        "          label='Estimated PDF', c='tab:orange')\n",
        "  plt.xscale('log')\n",
        "  plt.yscale('log')\n",
        "  plt.legend();\n",
        "  plt.savefig(save_to+'degree_in_estim.png')\n",
        "  plt.close('All')\n",
        "  print('Power law params: gamma=', round(hat_alpha, 4), 'k_min=', hat_x_min)\n",
        "  if isinstance(csv, pd.DataFrame):\n",
        "    csv.loc[num, 'gamma']=round(hat_alpha, 4)\n",
        "    csv.loc[num, 'k_min']=hat_x_min\n",
        "\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  plt.figure(figsize=(8, 6), dpi=200) #plotting distribution of local clustering coefficients\n",
        "  plt.title(\"Local clustering coefficient distribution\")\n",
        "  plt.xlabel(\"Clustering coefficient\")\n",
        "  plt.ylabel(\"Number of nodes\")\n",
        "  plt.hist(list(nx.clustering(G).values()), bins=20) #dispersed in 20 bins automatically\n",
        "  plt.savefig(save_to+'LCC.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  s=list(set(list(dict(G.in_degree).values())))\n",
        "  maps={s[i]: i for i in range(len(s))}\n",
        "  mix=nx.degree_mixing_matrix(G, x='in', y='in', mapping=maps)\n",
        "  deg={(i, j): mix[i, j] for i in range(mix.shape[0]) for j in range(i, mix.shape[1])}\n",
        "  print(\"Assortativity coefficient (in-in):\", round(nx.degree_pearson_correlation_coefficient(G, x='in', y='in'), 4))\n",
        "  if isinstance(csv, pd.DataFrame):\n",
        "    csv.loc[num, 'AII']=round(nx.degree_pearson_correlation_coefficient(G, x='in', y='in'), 4)\n",
        "\n",
        "  # for i, j in sorted(deg, key=deg.get, reverse=True)[:20]:\n",
        "  #     k=deg[(i,j)]\n",
        "  #     if k>0:\n",
        "  #         print(s[i], s[j], k)\n",
        "  plt.figure(figsize=(12, 8),dpi=200)\n",
        "  k=max(1,len(maps)//10)\n",
        "  r=sns.heatmap(\n",
        "          mix[-1::-1])\n",
        "  r.set_xticks(list(maps.values())[::k], labels=list(maps.values())[::k])\n",
        "  r.set_yticks(list(maps.values())[::k], labels=list(maps.values())[::k][-1::-1])\n",
        "  plt.title(\"Degree correlation matrix (in-degree vs in-degree)\")\n",
        "  plt.savefig(save_to+'DCM_in_in.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  x=np.array(sorted(set(dict(G.in_degree()).values()))).reshape(-1,1)\n",
        "  z=nx.average_degree_connectivity(G, source='in', target='in')\n",
        "  y=np.array([z[i[0]] for i in x]).reshape(-1,1)\n",
        "  lin_reg = LinearRegression()\n",
        "  lin_reg.fit(x, y)\n",
        "  pr=lin_reg.predict(x)\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  plt.figure(figsize=(8,6), dpi=200)\n",
        "  plt.scatter(x,y, label='func')\n",
        "  plt.plot(x,pr, color='orange', label='fit')\n",
        "  plt.xlabel('degree')\n",
        "  plt.ylabel('DCF')\n",
        "  plt.title('DCF (in-degree vs in-degree)')\n",
        "  plt.legend()\n",
        "  plt.savefig(save_to+'DCF_in_in.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  s=list(set(list(dict(G.out_degree).values())))\n",
        "  maps={s[i]: i for i in range(len(s))}\n",
        "  mix=nx.degree_mixing_matrix(G, x='out', y='out', mapping=maps)\n",
        "  deg={(i, j): mix[i, j] for i in range(mix.shape[0]) for j in range(i, mix.shape[1])} #same top as for cities\n",
        "  print(\"Assortativity coefficient (out-out):\", round(nx.degree_pearson_correlation_coefficient(G, x='out', y='out'), 4))\n",
        "  if isinstance(csv, pd.DataFrame):\n",
        "    csv.loc[num, 'AOO']=round(nx.degree_pearson_correlation_coefficient(G, x='out', y='out'), 4)\n",
        "  # for i, j in sorted(deg, key=deg.get, reverse=True)[:20]:\n",
        "  #     k=deg[(i,j)]\n",
        "  #     if k>0:\n",
        "  #         print(s[i], s[j], k)\n",
        "  plt.figure(figsize=(12, 8),dpi=200)\n",
        "  k=max(1,len(maps)//10)\n",
        "  r=sns.heatmap(\n",
        "          mix[-1::-1])\n",
        "  r.set_xticks(list(maps.values())[::k], labels=list(maps.values())[::k])\n",
        "  r.set_yticks(list(maps.values())[::k], labels=list(maps.values())[::k][-1::-1])\n",
        "  plt.title(\"Degree correlation matrix (out-degree vs out-degree)\")\n",
        "  plt.savefig(save_to+'DCM_out_out.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  x=np.array(sorted(set(dict(G.out_degree()).values()))).reshape(-1,1)\n",
        "  z=nx.average_degree_connectivity(G, source='out', target='out')\n",
        "  y=np.array([z[i[0]] for i in x]).reshape(-1,1)\n",
        "  lin_reg = LinearRegression()\n",
        "  lin_reg.fit(x, y)\n",
        "  pr=lin_reg.predict(x)\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  plt.figure(figsize=(8,6), dpi=200)\n",
        "  plt.scatter(x,y, label='func')\n",
        "  plt.plot(x,pr, color='orange', label='fit')\n",
        "  plt.xlabel('degree')\n",
        "  plt.ylabel('DCF')\n",
        "  plt.title('DCF (out-degree vs out-degree)')\n",
        "  plt.legend()\n",
        "  plt.savefig(save_to+'DCF_out_out.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  s=list(set(list(dict(G.in_degree).values())))\n",
        "  maps={s[i]: i for i in range(len(s))}\n",
        "  mix=nx.degree_mixing_matrix(G, x='in', y='out', mapping=maps)\n",
        "  deg={(i, j): mix[i, j] for i in range(mix.shape[0]) for j in range(i, mix.shape[1])} #same top as for cities\n",
        "  print(\"Assortativity coefficient (in-out):\", round(nx.degree_pearson_correlation_coefficient(G, x='in', y='out'), 4))\n",
        "  if isinstance(csv, pd.DataFrame):\n",
        "    csv.loc[num, 'AIO']=round(nx.degree_pearson_correlation_coefficient(G, x='in', y='out'), 4)\n",
        "  # for i, j in sorted(deg, key=deg.get, reverse=True)[:20]:\n",
        "  #     k=deg[(i,j)]\n",
        "  #     if k>0:\n",
        "  #         print(s[i], s[j], k)\n",
        "  plt.figure(figsize=(12, 8),dpi=200)\n",
        "  k=max(1,len(maps)//10)\n",
        "  r=sns.heatmap(\n",
        "          mix[-1::-1])\n",
        "  r.set_xticks(list(maps.values())[::k], labels=list(maps.values())[::k])\n",
        "  r.set_yticks(list(maps.values())[::k], labels=list(maps.values())[::k][-1::-1])\n",
        "  plt.title(\"Degree correlation matrix (in-degree vs out-degree)\")\n",
        "  plt.savefig(save_to+'DCM_in_out.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  x=np.array(sorted(set(dict(G.in_degree()).values()))).reshape(-1,1)\n",
        "  z=nx.average_degree_connectivity(G, source='in', target='out')\n",
        "  y=np.array([z[i[0]] for i in x]).reshape(-1,1)\n",
        "  lin_reg = LinearRegression()\n",
        "  lin_reg.fit(x, y)\n",
        "  pr=lin_reg.predict(x)\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  plt.figure(figsize=(8,6), dpi=200)\n",
        "  plt.scatter(x,y, label='func')\n",
        "  plt.plot(x,pr, color='orange', label='fit')\n",
        "  plt.xlabel('degree')\n",
        "  plt.ylabel('DCF')\n",
        "  plt.title('DCF (in-degree vs out-degree)')\n",
        "  plt.legend()\n",
        "  plt.savefig(save_to+'DCF_in_out.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  s=list(set(list(dict(G.out_degree).values())))\n",
        "  maps={s[i]: i for i in range(len(s))}\n",
        "  mix=nx.degree_mixing_matrix(G, x='out', y='in', mapping=maps)\n",
        "  deg={(i, j): mix[i, j] for i in range(mix.shape[0]) for j in range(i, mix.shape[1])} #same top as for cities\n",
        "  print(\"Assortativity coefficient (out-in):\", round(nx.degree_pearson_correlation_coefficient(G, x='out', y='in'), 4))\n",
        "  if isinstance(csv, pd.DataFrame):\n",
        "    csv.loc[num, 'AOI']=round(nx.degree_pearson_correlation_coefficient(G, x='out', y='in'), 4)\n",
        "  # for i, j in sorted(deg, key=deg.get, reverse=True)[:20]:\n",
        "  #     k=deg[(i,j)]\n",
        "  #     if k>0:\n",
        "  #         print(s[i], s[j], k)\n",
        "  plt.figure(figsize=(12, 8),dpi=200)\n",
        "  k=max(1,len(maps)//10)\n",
        "  r=sns.heatmap(\n",
        "          mix[-1::-1])\n",
        "  r.set_xticks(list(maps.values())[::k], labels=list(maps.values())[::k])\n",
        "  r.set_yticks(list(maps.values())[::k], labels=list(maps.values())[::k][-1::-1])\n",
        "  plt.title(\"Degree correlation matrix (out-degree vs in-degree)\")\n",
        "  plt.savefig(save_to+'DCM_out_in.png')\n",
        "  plt.close('All')\n",
        "\n",
        "  x=np.array(sorted(set(dict(G.out_degree()).values()))).reshape(-1,1)\n",
        "  z=nx.average_degree_connectivity(G, source='out', target='in')\n",
        "  y=np.array([z[i[0]] for i in x]).reshape(-1,1)\n",
        "  lin_reg = LinearRegression()\n",
        "  lin_reg.fit(x, y)\n",
        "  pr=lin_reg.predict(x)\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  plt.figure(figsize=(8, 6), dpi=200)\n",
        "  plt.scatter(x,y, label='func')\n",
        "  plt.plot(x,pr, color='orange', label='fit')\n",
        "  plt.xlabel('degree')\n",
        "  plt.ylabel('DCF')\n",
        "  plt.title('DCF (out-degree vs in-degree)')\n",
        "  plt.legend()\n",
        "  plt.savefig(save_to+'DCF_out_in.png')\n",
        "  plt.close('All')\n",
        "  ec=nx.eigenvector_centrality(G, max_iter=10000) #plotting graph - for clusters - comment if not needed\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)):\n",
        "    if m<10:\n",
        "      print(j, ' -- ', round(ec[j], 4), end=', ')\n",
        "      last=ec[j]\n",
        "      if isinstance(csv, pd.DataFrame): \n",
        "        csv.loc[num, m]=j\n",
        "  if len(G)<500:\n",
        "    plt.figure(figsize=(30, 12), dpi=600)\n",
        "    pos = nx.spring_layout(G)\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=[min(i*20*3.7**(i*15)+20, 0.35*20*3.7**(0.35*15)+20) for i in ec.values()], alpha=0.7,  node_color=[i for i in ec.values()], cmap=plt.cm.Oranges)\n",
        "    nx.draw_networkx_edges(G, pos, alpha=0.08)\n",
        "    for params in labels_list_parameters1(G, pos, ec, 25, last):\n",
        "        nx.draw_networkx_labels(**params)\n",
        "    plt.savefig(save_to+'layout.jpeg')\n",
        "    plt.close('all')\n",
        "  return csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UOdvBm29N5u"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS38HwL5nc3F"
      },
      "outputs": [],
      "source": [
        "def NB(G, save_to='', A=False, vals=False, vals1=False, dir=False, num=100, LM=False):\n",
        "#calculate NB matrix, its num largest and smallest real part eigenvalues, plot them with circles\n",
        "  shutil.copytree(path_in+'el_lib', 'el_lib')\n",
        "  from el_lib import Alpha\n",
        "  if dir:\n",
        "    adj_sym=nx.to_numpy_array(G, weight=None)\n",
        "    graph_sym = nx.from_numpy_array(adj_sym, create_using=nx.DiGraph)\n",
        "    all_edg_sym = np.array(graph_sym.edges())\n",
        "  else:\n",
        "    pipeline_object = Alpha(G)\n",
        "    adj = pipeline_object.adjacency_mat()\n",
        "    _, adj_sym = pipeline_object.preprocessing_matrix(adj)\n",
        "    all_edg_sym = pipeline_object.edges_extracting(adj_sym)\n",
        "  if vals:\n",
        "    vals_flow=np.load(vals)\n",
        "    if vals1:\n",
        "      vals_flow1=np.load(vals1)\n",
        "      vals_flow=np.hstack([vals_flow, vals_flow1])\n",
        "  else: \n",
        "    if A:\n",
        "      A=scipy.sparse.load_npz(A)\n",
        "    else:\n",
        "      nds={int(i):[] for i in G.nodes()}\n",
        "      ed={i: [] for i in range(all_edg_sym.shape[0])}\n",
        "      for i in range(all_edg_sym.shape[0]):\n",
        "        k, l = all_edg_sym[i]\n",
        "        nds[k].append(i)\n",
        "      for i in nds:\n",
        "          if not i%500:\n",
        "              print(i)\n",
        "          for j in nds[i]:\n",
        "              k, l = all_edg_sym[j]\n",
        "              for m in nds[l]:\n",
        "                q, r = all_edg_sym[m]\n",
        "                if not r==k:\n",
        "                  ed[j].append(m)\n",
        "      degrees = np.sum(adj_sym, axis=1)\n",
        "      B=np.zeros((1000, np.shape(all_edg_sym)[0]))\n",
        "      s=0000\n",
        "      m=0000\n",
        "      file='NB_A.npz'\n",
        "      for i in range(s, np.shape(all_edg_sym)[0]):\n",
        "          for j in ed[i]:\n",
        "            if degrees[all_edg_sym[j][0]] > 1:\n",
        "              B[i%1000][j] = 1/(degrees[all_edg_sym[j][0]] - 1)\n",
        "            else: \n",
        "              B[i%1000][j] = 1\n",
        "          if not (i+1)%1000 and i>0:\n",
        "            if not (i+1)%10000:\n",
        "              print(i/np.shape(all_edg_sym)[0]*100, end='% ')\n",
        "            if i==m+999:\n",
        "              A=scipy.sparse.csr_matrix(B)\n",
        "            else:\n",
        "              A=scipy.sparse.vstack([A, scipy.sparse.csr_matrix(B)])\n",
        "            B=np.zeros((1000, np.shape(all_edg_sym)[0]))\n",
        "            if (i+1)%50000==0:\n",
        "              scipy.sparse.save_npz(save_to+file, A)\n",
        "              print('save')\n",
        "              print(asizeof.asizeof(A)/1024/1024, end=' ')\n",
        "              print(A.shape, A.nnz)\n",
        "      if i<999:\n",
        "        A=scipy.sparse.csr_matrix(B)\n",
        "      else:\n",
        "        A=scipy.sparse.vstack([A, scipy.sparse.csr_matrix(B)])\n",
        "      A=A[:np.shape(all_edg_sym)[0]-m]\n",
        "      scipy.sparse.save_npz(save_to+file, A)\n",
        "      print(A.shape, A.nnz)\n",
        "    if LM:\n",
        "      vals_flow=scipy.sparse.linalg.eigs(A, min(A.shape[0]-2, num), which='LM', return_eigenvectors=False)\n",
        "      np.save(save_to+'val_flow.npy', vals_flow)\n",
        "      print('0')\n",
        "    else:\n",
        "      vals_flow=scipy.sparse.linalg.eigs(A, min(A.shape[0]-2, num), which='LR', return_eigenvectors=False)\n",
        "      np.save(save_to+'val_flow.npy', vals_flow)\n",
        "      print('1')\n",
        "      if A.shape[0]>num:\n",
        "        vals_flow1=scipy.sparse.linalg.eigs(A, min(A.shape[0]-2, num), which='SR',  return_eigenvectors=False)\n",
        "        np.save(save_to+'/val_flow1.npy', vals_flow1)\n",
        "        print('2')\n",
        "        vals_flow=np.hstack([vals_flow, vals_flow1])\n",
        "  degrees = np.sum(adj_sym, axis=1)\n",
        "  cr_rad = np.sqrt(np.mean(np.array(degrees)/(np.array([x-1 if x>1 else max(x, 1) for x in degrees])))/(np.mean(degrees)))\n",
        "  vals_sorted = vals_flow[vals_flow > cr_rad]\n",
        "  order = np.argsort(-np.abs(np.array(vals_sorted)))\n",
        "  max_clust_num=1000\n",
        "  vals_sorted = np.array(vals_sorted)[order[1:max_clust_num]] \n",
        "  tail = np.shape(vals_sorted)[0]\n",
        "  cr_rad, tail\n",
        "  ld=(adj_sym.sum(axis=1)).max()\n",
        "  avd=adj_sym.sum(axis=1).mean()\n",
        "  r1=1/np.sqrt(max(avd-1, 1e-20))\n",
        "  r2=1/(ld-1)\n",
        "  r3=1\n",
        "  plt.figure(figsize = (10, 10), dpi=200)\n",
        "  plt.scatter(vals_flow.real, vals_flow.imag)\n",
        "  plt.scatter(vals_sorted.real, vals_sorted.imag)\n",
        "  circle1 = plt.Circle((0, 0), cr_rad, color='r', fill=False, linestyle='--', alpha=0.5, label='critical radius')\n",
        "  plt.gca().add_patch(circle1)\n",
        "  plt.title(\"Non-backtracking Laplacian spectrum\")\n",
        "  plt.legend()\n",
        "  plt.savefig(save_to+'/vals.jpeg')\n",
        "  vals_flow=1-vals_flow\n",
        "  plt.figure(figsize = (10, 10), dpi=200)\n",
        "  plt.scatter(vals_flow.real, vals_flow.imag)\n",
        "  circle1 = plt.Circle((1, 0), r1, color='r', fill=False, linestyle='--', alpha=0.5, label=r'$\\frac{1}{\\sqrt{\\alpha-1}}$')\n",
        "  plt.gca().add_patch(circle1)\n",
        "  circle2 = plt.Circle((1, 0), r2, color='g', fill=False, linestyle='--', alpha=0.5, label=r'$\\frac{1}{\\Delta-1}$')\n",
        "  plt.gca().add_patch(circle2)\n",
        "  circle3 = plt.Circle((1, 0), r3, color='y', fill=False, linestyle='--', alpha=0.5, label='1')\n",
        "  plt.gca().add_patch(circle3)\n",
        "  plt.title(\"Non-backtracking Laplacian spectrum\")\n",
        "  plt.legend()\n",
        "  plt.savefig(save_to+'/vals2.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGaDjiV88nV5"
      },
      "outputs": [],
      "source": [
        "def filter(G, p=0.1): #filter edges by weight\n",
        "  m=min(int(G.number_of_edges()*p), G.number_of_edges()-1)\n",
        "  A=nx.to_numpy_array(G)\n",
        "  w=sorted(nx.get_edge_attributes(G, 'weight').values(), reverse=True)[m]\n",
        "  A[A<w]=0\n",
        "  return nx.DiGraph(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvsnnOCb8nTj"
      },
      "outputs": [],
      "source": [
        "def calc_triangles(G, p_start=0, weighted=True): #calculate distribution of triangles\n",
        "  stat=np.zeros((4, len(np.arange(p_start, 1.01, 0.1))))\n",
        "  for num, p in enumerate(np.arange(p_start, 1.01, 0.1)):\n",
        "    if weighted:\n",
        "      sub=filter(G, p)\n",
        "    else:\n",
        "      sub=G\n",
        "    t_type=np.zeros(4)\n",
        "    ne=0\n",
        "    sub2=nx.to_undirected(sub)\n",
        "    for (i, j) in sub.edges():\n",
        "      t=np.zeros(4)\n",
        "      neig=nx.common_neighbors(sub2, i, j)\n",
        "      for k in neig:\n",
        "        if (j, k) in sub.edges() and (k, i) in sub.edges():\n",
        "          t[0]+=1\n",
        "        elif (k, j) in sub.edges() and (k, i) in sub.edges():\n",
        "          t[1]+=1\n",
        "        elif (j, k) in sub.edges() and (i, k) in sub.edges():\n",
        "          t[2]+=1\n",
        "        elif (i, k) in sub.edges() and (k, j) in sub.edges():\n",
        "          t[3]+=1\n",
        "      t=t/t.sum() if t.sum()>0 else t\n",
        "      if t.sum()>0:\n",
        "        ne+=1\n",
        "        t_type+=t\n",
        "    stat[:, num]=t_type/ne if ne>0 else t_type\n",
        "  return stat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grGMnhFlpsEj"
      },
      "outputs": [],
      "source": [
        "def gen(n, m1=1, p=0.1): #model GEN1\n",
        "  G=nx.erdos_renyi_graph(20, 0.1, directed=True)\n",
        "  for i in range(20, n):\n",
        "    if not i%(n//10):\n",
        "      print(i)\n",
        "    probs={}\n",
        "    for j, k in G.edges():\n",
        "      probs[(j, k)]=G.degree[j]+G.degree[k]\n",
        "    m=list(probs.keys())\n",
        "    p=np.array(list(probs.values()))\n",
        "    p=p/p.sum()\n",
        "    t=np.random.choice([i for i in range(len(m))], 3*m1, False, p) #add triangles type 2-4\n",
        "    for num, j in enumerate(t):\n",
        "      k, l = m[j]\n",
        "      if num%3==0:\n",
        "        G.add_edge(i, k)\n",
        "        G.add_edge(i, l)\n",
        "      elif num%3==1:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(l, i)\n",
        "      elif num%3==2:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(i, l)\n",
        "    j=0\n",
        "    while not j==6*m1: #random edges\n",
        "      k, l = np.random.choice(list(G.nodes()), 2, False)\n",
        "      if not (k, l) in G.edges():\n",
        "        G.add_edge(k, l)\n",
        "        j+=1\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeqOYX0hpsEl"
      },
      "outputs": [],
      "source": [
        "def gen2(n, tri, m1=1, p=0.1): #GEN2\n",
        "  G=nx.erdos_renyi_graph(20, p, directed=True)\n",
        "  for i in range(20, n):\n",
        "    if not i%(n//10):\n",
        "      print(i)\n",
        "    probs={}\n",
        "    for j, k in G.edges():\n",
        "      probs[(j, k)]=G.degree[j]+G.degree[k]\n",
        "    m=list(probs.keys())\n",
        "    p=np.array(list(probs.values()))\n",
        "    p=p/p.sum()\n",
        "    t=np.random.choice([i for i in range(len(m))], 4*m1, False, p)\n",
        "\n",
        "    for j in t:\n",
        "      num=np.random.choice([i for i in range(4)], 1, p=tri)[0] #triangles any type\n",
        "      k, l = m[j]\n",
        "      if num==0:\n",
        "        G.add_edge(l, i)\n",
        "        G.add_edge(i, k)\n",
        "      elif num==1:\n",
        "        G.add_edge(i, k)\n",
        "        G.add_edge(i, l)\n",
        "      elif num==2:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(l, i)\n",
        "      elif num==3:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(i, l)\n",
        "    j=0\n",
        "    while not j==4*m1:\n",
        "      k, l = np.random.choice(list(G.nodes()), 2, False)\n",
        "      if not (k, l) in G.edges():\n",
        "        G.add_edge(k, l)\n",
        "        j+=1\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvxmsycNpsEm"
      },
      "outputs": [],
      "source": [
        "def gen3(n, tri, load=False, file='net.graphml', m1=1, p=0.1): #GEN3\n",
        "  if load:\n",
        "    G=nx.read_graphml(file)\n",
        "  else:\n",
        "    G=nx.erdos_renyi_graph(20, p, directed=True)\n",
        "  tri_use=tri.copy()\n",
        "  for i in range(len(G), n):\n",
        "    if load:\n",
        "      i=str(i)\n",
        "    probs={}\n",
        "    for j, k in G.edges():\n",
        "      probs[(j, k)]=G.degree[j]+G.degree[k]\n",
        "    m=list(probs.keys())\n",
        "    p=np.array(list(probs.values()))\n",
        "    p=p/p.sum()\n",
        "    t=np.random.choice([i for i in range(len(m))], 4*m1, False, p)\n",
        "\n",
        "    for j in t:\n",
        "      num=np.random.choice([i for i in range(4)], 1, p=tri_use)[0]\n",
        "      k, l = m[j]\n",
        "      if num==0:\n",
        "        G.add_edge(l, i)\n",
        "        G.add_edge(i, k)\n",
        "      elif num==1:\n",
        "        G.add_edge(i, k)\n",
        "        G.add_edge(i, l)\n",
        "      elif num==2:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(l, i)\n",
        "      elif num==3:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(i, l)\n",
        "    j=0\n",
        "    while not j==4*m1:\n",
        "      k, l = np.random.choice(list(G.nodes()), 2, False)\n",
        "      if not (k, l) in G.edges():\n",
        "        G.add_edge(k, l)\n",
        "        j+=1\n",
        "    if not int(i)%(n//100):\n",
        "      tri_upd=calc_triangles(G, 1, False)[:,0] #update triangles distribution\n",
        "      tri_use=np.array([max(0, i) for i in 2*tri-tri_upd])\n",
        "      tri_use=tri_use/tri_use.sum()\n",
        "    if not int(i)%(n//10):\n",
        "      nx.write_graphml(G, file)\n",
        "      print(i)\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoYPkAY6ZpAN"
      },
      "outputs": [],
      "source": [
        "def DL(G, to, num=300): #find normalised directed laplacian eigs\n",
        "  A=nx.to_scipy_sparse_array(G)\n",
        "  B=(A.T/A.sum(1)).T\n",
        "  e, u = scipy.sparse.linalg.eigs(B, k=1, which='LR')\n",
        "  S = np.abs(u).squeeze()\n",
        "  S=S/S.sum()\n",
        "  F=scipy.sparse.diags(S)\n",
        "  F1=F.power(1/2)\n",
        "  F2=F.power(-1/2)\n",
        "  L=(F1@B@F2+F2@B.T@F1)/2\n",
        "  L=scipy.sparse.csr_matrix(L)\n",
        "  print('L')\n",
        "  e, u=scipy.sparse.linalg.eigs(L, num, which='LR')\n",
        "  plt.figure(figsize = (10, 10), dpi=200)\n",
        "  plt.scatter(e.real, e.imag)\n",
        "  # plt.axis('off')\n",
        "  plt.show()\n",
        "  plt.savefig(path_out+name+to+'vals1.jpeg')\n",
        "  print('fin')\n",
        "  return L\n",
        "\n",
        "def DL_2(G, Gr, to, num=300): #find NDL eigs and compare to real (for models)\n",
        "  A=nx.to_scipy_sparse_array(G)\n",
        "  B=(A.T/A.sum(1)).T\n",
        "  e, u = scipy.sparse.linalg.eigs(B, k=1, which='LR')\n",
        "  S = np.abs(u).squeeze()\n",
        "  S=S/S.sum()\n",
        "  F=scipy.sparse.diags(S)\n",
        "  F1=F.power(1/2)\n",
        "  F2=F.power(-1/2)\n",
        "  L=(F1@B@F2+F2@B.T@F1)/2\n",
        "  L=scipy.sparse.csr_matrix(L)\n",
        "  print('L')\n",
        "  e, u=scipy.sparse.linalg.eigs(L, num, which='LR')\n",
        "  A=nx.to_scipy_sparse_array(Gr)\n",
        "  B=(A.T/A.sum(1)).T\n",
        "  er, ur = scipy.sparse.linalg.eigs(B, k=1, which='LR')\n",
        "  S = np.abs(ur).squeeze()\n",
        "  S=S/S.sum()\n",
        "  F=scipy.sparse.diags(S)\n",
        "  F1=F.power(1/2)\n",
        "  F2=F.power(-1/2)\n",
        "  L=(F1@B@F2+F2@B.T@F1)/2\n",
        "  L=scipy.sparse.csr_matrix(L)\n",
        "  print(\"L\")\n",
        "  er, ur=scipy.sparse.linalg.eigs(L, num, which='LR')\n",
        "  plt.figure(figsize = (10, 10), dpi=200)\n",
        "  plt.scatter(e.real, e.imag, label='simulated')\n",
        "  plt.savefig(path_out+name+to+'vals1.jpeg')\n",
        "  plt.scatter(er.real, er.imag, label='real')\n",
        "  # plt.axis('off')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.savefig(path_out+name+to+'c_vals1.jpeg')\n",
        "  print('fin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzYb0_2SZpAO"
      },
      "outputs": [],
      "source": [
        "def BH(G, Gr=None, to='', num=300, ret=True): #find bethe hessian eigs, return or compare if model\n",
        "    r=np.sqrt(np.array(list(dict(G.degree()).values())).mean())\n",
        "    B=nx.bethe_hessian_matrix(G.to_undirected(), r=r)\n",
        "    e, u=scipy.sparse.linalg.eigs(B, 300, which='SR')\n",
        "    if ret:\n",
        "      k=np.where(e.real<0)[0]\n",
        "      return u[:k]\n",
        "    plt.figure(figsize = (10, 10), dpi=200)\n",
        "    plt.scatter(e.real, e.imag, label='simulated')\n",
        "    plt.savefig(path_out+name+to+'vals.jpeg')\n",
        "    print('B')\n",
        "    r=np.sqrt(np.array(list(dict(Gr.degree()).values())).mean())\n",
        "    B=nx.bethe_hessian_matrix(Gr.to_undirected(), r=r)\n",
        "    er, ur=scipy.sparse.linalg.eigs(B, num, which='SR')\n",
        "    plt.scatter(er.real, er.imag, label='real')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.savefig(path_out+name+to+'c_vals.jpeg')\n",
        "    print('B')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b03GqDLOpiwx"
      },
      "outputs": [],
      "source": [
        "def spectral_clustering(embedding, n_clusters=100):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=1000, max_iter=10000)\n",
        "    kmeans.fit(embedding)\n",
        "    return kmeans.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_hWDv5KpsEg"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF5EQ--ApsEi"
      },
      "outputs": [],
      "source": [
        "stat=calc_triangles(G) #calculate triangles distribution in real graph\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'tri.csv')\n",
        "stat=np.array(pd.read_csv(path_out+name+'self/tri.csv'))\n",
        "tri=stat[-1, 1:]\n",
        "tri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWcKkRPSpsEj"
      },
      "outputs": [],
      "source": [
        "x=np.arange(0, 1+0.1, 0.1)\n",
        "plt.figure(figsize=(8, 6), dpi=200)\n",
        "for i in range(4):\n",
        "  plt.plot(x, stat[i], label=str(i+1)+' type')\n",
        "plt.legend()\n",
        "plt.savefig(path_out+name+'tri_stats.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5rQqOxLZRw-"
      },
      "outputs": [],
      "source": [
        "num=1000\n",
        "suf=''\n",
        "tab=True\n",
        "tab_name='models2.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IU7KXFQ6yRwj"
      },
      "outputs": [],
      "source": [
        "tab=pd.read_csv(path_out+name+tab_name, index_col=0)\n",
        "tab.columns=[int(i) if i in [str(j) for j in range(10)] else i for i in tab.columns]\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz8ceh2EyaS0"
      },
      "outputs": [],
      "source": [
        "def BA(n, m): #directed preferential attachment\n",
        "  m0=max(int(m//n), 2)\n",
        "  G=nx.DiGraph()\n",
        "  G.add_node(0)\n",
        "  for i in range(1, m0):\n",
        "    G.add_edge(i, 0)\n",
        "  # print(G.degree())\n",
        "  for i in range(m0, n):\n",
        "    p=np.array(list(dict(G.degree()).values()))\n",
        "    p=p/p.sum()\n",
        "    to=np.random.choice(list(G.nodes()), m0, False, p)\n",
        "    for k in to:\n",
        "      G.add_edge(i, k)\n",
        "    if not i%(n//10):\n",
        "      print(i)\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU9MekBVVUia"
      },
      "outputs": [],
      "source": [
        "num=len(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMzIhcSZyhwz"
      },
      "outputs": [],
      "source": [
        "m=G.number_of_edges()\n",
        "m=nx.density(G)*num**2\n",
        "G_BA=BA(num, m)\n",
        "nx.write_graphml(G_BA, path_out+name+'BA_'+str(num)+suf+'.graphml')\n",
        "if not os.path.exists(path_out+name+'BA_'+str(num)+suf+'/'):\n",
        "  os.makedirs(path_out+name+'BA_'+str(num)+suf+'/')\n",
        "stat=calc_triangles(G_BA, 1, False)\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'triBA_'+str(num)+suf+'.csv')\n",
        "calculate_graph_features(G_BA, path_out+name+'BA_'+str(num)+suf+'/', tab, 'BA_'+str(num)+suf+'')\n",
        "tab.to_csv(path_out+name+tab_name)\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNkkmyuY5isr"
      },
      "outputs": [],
      "source": [
        "def SB(n, m, c_num, p_blocks, sizes=0): #stochastic block\n",
        "  print(m)\n",
        "  G=nx.DiGraph()\n",
        "  if not isinstance(sizes, np.ndarray):\n",
        "    sizes=np.array([int(n/c_num) for i in range(c_num)])\n",
        "    sizes[-1]+=n-sizes.sum()\n",
        "  st=0\n",
        "  for i in range(0, c_num):\n",
        "    for j in range(sizes[i]):\n",
        "      G.add_node(st+j)\n",
        "      G.nodes()[st+j]['block']=i\n",
        "    st+=sizes[i]\n",
        "  i=0\n",
        "  while not G.number_of_edges()>=m:\n",
        "    k=np.random.choice(G.nodes(), 1)[0]\n",
        "    cl=G.nodes()[k]['block']\n",
        "    p=np.array([p_blocks[cl][G.nodes()[j]['block']] for j in G.nodes()])\n",
        "    p=p/p.sum()\n",
        "    l=np.random.choice(list(G.nodes()), 1, p=p)[0]\n",
        "    if not (k, l) in G.edges() and not k==l:\n",
        "      G.add_edge(k, l)\n",
        "      i+=1\n",
        "      if not i%(m//20):\n",
        "        print(i)\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr8ZvElbVn8j"
      },
      "outputs": [],
      "source": [
        "G_ref = nx.read_graphml(path_out+\"dutch/DL/31/clustered.graphml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm68IngWVn8l"
      },
      "outputs": [],
      "source": [
        "G_ref = nx.read_graphml(path_out+\"dutch/NB/clustered.graphml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAheREHFVn8m"
      },
      "outputs": [],
      "source": [
        "G_ref = nx.read_graphml(path_out+\"dutch/NB2/clustered.graphml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-tmZxtmAUGu"
      },
      "outputs": [],
      "source": [
        "cl_best=np.array([G_ref.nodes[i]['clust'] for i in G_ref.nodes()]) #clustering to mimic\n",
        "mk=len(set(cl_best))\n",
        "cl_A=np.zeros((mk, mk))\n",
        "cl_nn=np.zeros(mk)\n",
        "ns=list(G_ref.nodes)\n",
        "for i in G_ref.nodes:\n",
        "  for j in G_ref.nodes:\n",
        "    if (i, j) in G_ref.edges():\n",
        "      cl_A[G_ref.nodes[i]['clust']][G_ref.nodes[j]['clust']]+=1\n",
        "cl_nn=[len(np.where(cl_best==i)[0]) for i in range(mk)]\n",
        "for i in range(mk):\n",
        "  for j in range(mk):\n",
        "    l=cl_nn[i]*cl_nn[j]\n",
        "    if i==j:\n",
        "      l=cl_nn[i]*(cl_nn[j]-1)\n",
        "    if not l==0:\n",
        "      cl_A[i][j]/=l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iNyHEkzZsCq"
      },
      "source": [
        "### SB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L--ZjhEPBhwC"
      },
      "outputs": [],
      "source": [
        "num=len(G)\n",
        "suf1='base10'\n",
        "suf='_0_'+suf1\n",
        "p=nx.density(G)\n",
        "m=p*num**2\n",
        "m=G.number_of_edges()\n",
        "sizes=0\n",
        "# sizes=np.array(cl_nn)\n",
        "# cl_num=len(cl_nn)\n",
        "cl_num=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gntVOfKw5kiZ"
      },
      "outputs": [],
      "source": [
        "G_SB=SB(num, m, cl_num, cl_A, sizes)\n",
        "nx.write_graphml(G_SB, path_out+name+'SB_'+str(num)+suf+'.graphml')\n",
        "if not os.path.exists(path_out+name+'SB_'+str(num)+suf+'/'):\n",
        "  os.makedirs(path_out+name+'SB_'+str(num)+suf+'/')\n",
        "# G_SB=nx.read_graphml(path_out+name+'SB_'+str(num)+suf+'.graphml')\n",
        "stat=calc_triangles(G_SB, 1, False)\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'triSB_'+str(num)+suf+'.csv')\n",
        "calculate_graph_features(G_SB, path_out+name+'SB_'+str(num)+suf+'/', tab, 'SB_'+str(num)+suf+'', diam=True)\n",
        "tab.to_csv(path_out+name+tab_name)\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImfiQ-oghWHX"
      },
      "outputs": [],
      "source": [
        "tab.to_csv(path_out+name+tab_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMfuiHViEdof"
      },
      "outputs": [],
      "source": [
        "def SB1(n, m1, c_num, p_blocks, sizes=0):\n",
        "  G=nx.DiGraph()\n",
        "  if not isinstance(sizes, np.ndarray):\n",
        "    sizes=np.array([int(n/c_num) for i in range(c_num)])\n",
        "    sizes[-1]+=n-sizes.sum()\n",
        "  else:\n",
        "    sizes=sizes.copy()\n",
        "  # print(sizes)\n",
        "  for i in range(0, c_num):\n",
        "    G.add_node(i)\n",
        "    G.nodes[i]['block']=i\n",
        "    sizes[i]-=1\n",
        "    if sizes[i]==0:\n",
        "      continue\n",
        "    for j in range(1, 3*m1+1):\n",
        "      G.add_edge(i+c_num*j, i)\n",
        "      G.nodes()[i]['block']=i\n",
        "      G.nodes()[i+c_num*j]['block']=i\n",
        "      sizes[i]-=1\n",
        "      if sizes[i]==0:\n",
        "        break\n",
        "  # print(sizes)\n",
        "  for i in range(len(G), n):\n",
        "    if not i%(n//10):\n",
        "      print(i)\n",
        "    p=sizes/sizes.sum()\n",
        "    bl=np.random.choice([i for i in range(c_num)], 1, p=p)[0] #choose block which needs nodes\n",
        "    probs={}\n",
        "    for j, k in G.edges(): #choose edges to form triangles (preferentially inside block, with very small probability outside)\n",
        "      probs[(j, k)]=G.degree[j]+G.degree[k] if G.nodes[j]['block']==bl and G.nodes[k]['block']==bl else 1e-50\n",
        "    m=list(probs.keys()) #do GEN1\n",
        "    p=np.array(list(probs.values()))\n",
        "    p=p/p.sum()\n",
        "    t=np.random.choice([i for i in range(len(m))], 3*m1, False, p)\n",
        "    for num, j in enumerate(t):\n",
        "      k, l = m[j]\n",
        "      if num%3==0:\n",
        "        G.add_edge(i, k)\n",
        "        G.add_edge(i, l)\n",
        "      elif num%3==1:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(l, i)\n",
        "      elif num%3==2:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(i, l)\n",
        "    j=0\n",
        "    G.nodes[i]['block']=bl\n",
        "    sizes[bl]-=1\n",
        "    while not j==6*m1:\n",
        "      k=np.random.choice(G.nodes(), 1)[0]\n",
        "      cl=G.nodes()[k]['block']\n",
        "      p=np.array([p_blocks[cl][G.nodes()[j]['block']] for j in G.nodes()])\n",
        "      p=p/p.sum()\n",
        "      l=np.random.choice(list(G.nodes()), 1, p=p)[0]\n",
        "      if not (k, l) in G.edges() and not k==l:\n",
        "        G.add_edge(k, l)\n",
        "        j+=1\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lVsOPtHJnUp"
      },
      "outputs": [],
      "source": [
        "suf='_1_'+suf1\n",
        "p=nx.density(G)\n",
        "m1=int(max(1, round(num*p/12)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-o9z8MxJkxi"
      },
      "outputs": [],
      "source": [
        "G_SB=SB1(num, m1, cl_num, cl_A)\n",
        "nx.write_graphml(G_SB, path_out+name+'SB_'+str(num)+suf+'.graphml')\n",
        "if not os.path.exists(path_out+name+'SB_'+str(num)+suf+'/'):\n",
        "  os.makedirs(path_out+name+'SB_'+str(num)+suf+'/')\n",
        "# G_SB=nx.read_graphml(path_out+name+'SB_'+str(num)+suf+'.graphml')\n",
        "stat=calc_triangles(G_SB, 1, False)\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'triSB_'+str(num)+suf+'.csv')\n",
        "calculate_graph_features(G_SB, path_out+name+'SB_'+str(num)+suf+'/', tab, 'SB_'+str(num)+suf+'', diam=0)\n",
        "tab.to_csv(path_out+name+tab_name)\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgugP59DhXJZ"
      },
      "outputs": [],
      "source": [
        "tab.to_csv(path_out+name+tab_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVWrSGdLGmY2"
      },
      "outputs": [],
      "source": [
        "def SB2(n, m1, c_num, p_blocks, tri, sizes=0):\n",
        "  G=nx.DiGraph()\n",
        "  if not isinstance(sizes, np.ndarray):\n",
        "    sizes=np.array([int(n/c_num) for i in range(c_num)])\n",
        "    sizes[-1]+=n-sizes.sum()\n",
        "  else:\n",
        "    sizes=sizes.copy()\n",
        "  st=0\n",
        "  for i in range(0, c_num):\n",
        "    G.add_node(i)\n",
        "    G.nodes[i]['block']=i\n",
        "    sizes[i]-=1\n",
        "    if sizes[i]==0:\n",
        "      continue\n",
        "    for j in range(1, 4*m1+1):\n",
        "      G.add_edge(i+c_num*j, i)\n",
        "      G.nodes()[i]['block']=i\n",
        "      G.nodes()[i+c_num*j]['block']=i\n",
        "      sizes[i]-=1\n",
        "      if sizes[i]==0:\n",
        "        break\n",
        "  for i in range(len(G), n):\n",
        "    if not i%(n//10):\n",
        "      print(i)\n",
        "    p=sizes/sizes.sum()\n",
        "    bl=np.random.choice([i for i in range(c_num)], 1, p=p)[0]\n",
        "    probs={}\n",
        "    for j, k in G.edges():\n",
        "      probs[(j, k)]=G.degree[j]+G.degree[k] if G.nodes[j]['block']==bl and G.nodes[k]['block']==bl else 1e-50\n",
        "    m=list(probs.keys())\n",
        "    p=np.array(list(probs.values()))\n",
        "    p=p/p.sum()\n",
        "    t=np.random.choice([i for i in range(len(m))], 4*m1, False, p)\n",
        "    for j in t:\n",
        "      num=np.random.choice([i for i in range(4)], 1, p=tri)[0]\n",
        "      k, l = m[j]\n",
        "      if num==0:\n",
        "        G.add_edge(l, i)\n",
        "        G.add_edge(i, k)\n",
        "      elif num==1:\n",
        "        G.add_edge(i, k)\n",
        "        G.add_edge(i, l)\n",
        "      elif num==2:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(l, i)\n",
        "      elif num==3:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(i, l)\n",
        "    j=0\n",
        "    G.nodes[i]['block']=bl\n",
        "    sizes[bl]-=1\n",
        "    while not j==4*m1:\n",
        "      k=np.random.choice(G.nodes(), 1)[0]\n",
        "      cl=G.nodes()[k]['block']\n",
        "      p=np.array([p_blocks[cl][G.nodes()[j]['block']] for j in G.nodes()])\n",
        "      p=p/p.sum()\n",
        "      l=np.random.choice(list(G.nodes()), 1, p=p)[0]\n",
        "      if not (k, l) in G.edges() and not k==l:\n",
        "        G.add_edge(k, l)\n",
        "        j+=1\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UzIzKOANvRl"
      },
      "outputs": [],
      "source": [
        "suf='_2_'+suf1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWf3sfLENvRn"
      },
      "outputs": [],
      "source": [
        "G_SB=SB2(num, m1, cl_num, cl_A, tri, sizes)\n",
        "nx.write_graphml(G_SB, path_out+name+'SB_'+str(num)+suf+'.graphml')\n",
        "if not os.path.exists(path_out+name+'SB_'+str(num)+suf+'/'):\n",
        "  os.makedirs(path_out+name+'SB_'+str(num)+suf+'/')\n",
        "# G_SB=nx.read_graphml(path_out+name+'SB_'+str(num)+suf+'.graphml')\n",
        "stat=calc_triangles(G_SB, 1, False)\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'triSB_'+str(num)+suf+'.csv')\n",
        "calculate_graph_features(G_SB, path_out+name+'SB_'+str(num)+suf+'/', tab, 'SB_'+str(num)+suf+'', diam=True)\n",
        "tab.to_csv(path_out+name+tab_name)\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Lf4cei0hX76"
      },
      "outputs": [],
      "source": [
        "tab.to_csv(path_out+name+tab_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01ZIJkhpIdgS"
      },
      "outputs": [],
      "source": [
        "def SB3(n, m1, c_num, p_blocks, tri, sizes=0, load=False, file='net.graphml'):\n",
        "  G=nx.DiGraph()\n",
        "  if load:\n",
        "    G=nx.read_graphml(file)\n",
        "  else:\n",
        "    if not isinstance(sizes, np.ndarray):\n",
        "      sizes=np.array([int(n/c_num) for i in range(c_num)])\n",
        "      sizes[-1]+=n-sizes.sum()\n",
        "    else:\n",
        "      sizes=sizes.copy()\n",
        "    for i in range(0, c_num):\n",
        "      G.add_node(i)\n",
        "      G.nodes[i]['block']=i\n",
        "      sizes[i]-=1\n",
        "      if sizes[i]==0:\n",
        "        continue\n",
        "      for j in range(1, 4*m1+1):\n",
        "        G.add_edge(i+c_num*j, i)\n",
        "        G.nodes()[i]['block']=i\n",
        "        G.nodes()[i+c_num*j]['block']=i\n",
        "        sizes[i]-=1\n",
        "        if sizes[i]==0:\n",
        "          break\n",
        "  tri_use=tri.copy()\n",
        "  for i in range(len(G), n):\n",
        "    if not i%(n//10):\n",
        "      nx.write_graphml(G, file)\n",
        "      print(i)\n",
        "    if load:\n",
        "      i=str(i)\n",
        "    p=sizes/sizes.sum()\n",
        "    bl=np.random.choice([i for i in range(c_num)], 1, p=p)[0]\n",
        "    probs={}\n",
        "    for j, k in G.edges():\n",
        "      probs[(j, k)]=G.degree[j]+G.degree[k] if G.nodes[j]['block']==bl and G.nodes[k]['block']==bl else 1e-50\n",
        "    m=list(probs.keys())\n",
        "    p=np.array(list(probs.values()))\n",
        "    p=p/p.sum()\n",
        "    t=np.random.choice([i for i in range(len(m))], 4*m1, False, p)\n",
        "    for j in t:\n",
        "      num=np.random.choice([i for i in range(4)], 1, p=tri_use)[0]\n",
        "      k, l = m[j]\n",
        "      if num==0:\n",
        "        G.add_edge(l, i)\n",
        "        G.add_edge(i, k)\n",
        "      elif num==1:\n",
        "        G.add_edge(i, k)\n",
        "        G.add_edge(i, l)\n",
        "      elif num==2:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(l, i)\n",
        "      elif num==3:\n",
        "        G.add_edge(k, i)\n",
        "        G.add_edge(i, l)\n",
        "    j=0\n",
        "    G.nodes[i]['block']=bl\n",
        "    sizes[bl]-=1\n",
        "    while not j==4*m1:\n",
        "      k=np.random.choice(G.nodes(), 1)[0]\n",
        "      cl=G.nodes()[k]['block']\n",
        "      p=np.array([p_blocks[cl][G.nodes()[j]['block']] for j in G.nodes()])\n",
        "      p=p/p.sum()\n",
        "      l=np.random.choice(list(G.nodes()), 1, p=p)[0]\n",
        "      if not (k, l) in G.edges() and not k==l:\n",
        "        G.add_edge(k, l)\n",
        "        j+=1\n",
        "    if not int(i)%(n//100):\n",
        "      tri_upd=calc_triangles(G, 1, False)[:,0]\n",
        "      tri_use=np.array([max(0, i) for i in 2*tri-tri_upd])\n",
        "      tri_use=tri_use/tri_use.sum()\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohoQt8b6NwaM"
      },
      "outputs": [],
      "source": [
        "suf='_3_'+suf1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9A77u5ONwaa"
      },
      "outputs": [],
      "source": [
        "G_SB=SB3(num, m1, cl_num, cl_A, tri, sizes, file=path_out+name+'SB_'+str(num)+suf+'.graphml', load=True)\n",
        "nx.write_graphml(G_SB, path_out+name+'SB_'+str(num)+suf+'.graphml')\n",
        "if not os.path.exists(path_out+name+'SB_'+str(num)+suf+'/'):\n",
        "  os.makedirs(path_out+name+'SB_'+str(num)+suf+'/')\n",
        "# G_SB=nx.read_graphml(path_out+name+'SB_'+str(num)+suf+'.graphml')\n",
        "stat=calc_triangles(G_SB, 1, False)\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'triSB_'+str(num)+suf+'.csv')\n",
        "calculate_graph_features(G_SB, path_out+name+'SB_'+str(num)+suf+'/', tab, 'SB_'+str(num)+suf+'', diam=1)\n",
        "tab.to_csv(path_out+name+tab_name)\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnwqkMm-roiG"
      },
      "outputs": [],
      "source": [
        "tab.to_csv(path_out+name+tab_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrTCMk4xdaeR"
      },
      "source": [
        "### GEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fewk-cfzpsEj"
      },
      "outputs": [],
      "source": [
        "p=nx.density(G)\n",
        "m1=max(1, round(num*p/12))\n",
        "m1\n",
        "G_gen=gen(num, m1, p)\n",
        "nx.write_graphml(G_gen, path_out+name+'GEN1_'+str(num)+suf+'.graphml')\n",
        "stat=calc_triangles(G_gen, 1, False)\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'triGEN1_'+str(num)+suf+'.csv')\n",
        "if not tab:  \n",
        "  tab=pd.DataFrame(columns=['nn', 'ne', 'diameter', 'radius', 'ASPL', 'transitivity', 'ACC', 'GCN', 'Density', 'Degree mean',\n",
        "                            'Degree var', 'In-degree mean', 'In-degree var', 'Out-degree mean', 'Out-degree var',\n",
        "                            'gamma', 'k_min', 'AII', 'AOO', \"AIO\", 'AOI', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "  if not os.path.exists(path_out+name+'self/'):\n",
        "    os.makedirs(path_out+name+'self/')\n",
        "  calculate_graph_features(G, path_out+name+'self/', tab, 'ORIG', diam=False)\n",
        "else:\n",
        "  tab=pd.read_csv(path_out+name+tab_name)\n",
        "  tab.columns=[int(i) if i in [str(j) for j in range(10)] else i for i in tab.columns]\n",
        "if not os.path.exists(path_out+name+'GEN1_'+str(num)+suf+'/'):\n",
        "  os.makedirs(path_out+name+'GEN1_'+str(num)+suf+'/')\n",
        "calculate_graph_features(G_gen, path_out+name+'GEN1_'+str(num)+suf+'/', tab, 'GEN1_'+str(num)+suf+'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cszBYTASpsEl"
      },
      "outputs": [],
      "source": [
        "G_ER=nx.erdos_renyi_graph(num, nx.density(G), directed=True)\n",
        "nx.write_graphml(G_ER, path_out+name+'ER_'+str(num)+suf+'.graphml')\n",
        "if not os.path.exists(path_out+name+'ER_'+str(num)+suf+'/'):\n",
        "  os.makedirs(path_out+name+'ER_'+str(num)+suf+'/')\n",
        "stat=calc_triangles(G_ER, 1, False)\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'triER_'+str(num)+suf+'.csv')\n",
        "calculate_graph_features(G_ER, path_out+name+'ER_'+str(num)+suf+'/', tab, 'ER_'+str(num)+suf+'')\n",
        "tab.to_csv(path_out+name+tab_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4iG5f_MJeDb"
      },
      "outputs": [],
      "source": [
        "m1=max(1, round(num*p/12))\n",
        "m1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bQ3RgFTpsEm"
      },
      "outputs": [],
      "source": [
        "G_gen2=gen2(num, tri, m1)\n",
        "nx.write_graphml(G_gen2, path_out+name+'GEN2_'+str(num)+suf+'.graphml')\n",
        "stat=calc_triangles(G_gen2, 1, False)\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'triGEN2_'+str(num)+suf+'.csv')\n",
        "if not os.path.exists(path_out+name+'GEN2_'+str(num)+suf+'/'):\n",
        "  os.makedirs(path_out+name+'GEN2_'+str(num)+suf+'/')\n",
        "G_gen2=nx.read_graphml(path_out+name+'GEN2_'+str(num)+suf+'.graphml')\n",
        "calculate_graph_features(G_gen2, path_out+name+'GEN2_'+str(num)+suf+'/', tab, 'GEN2_'+str(num)+suf+'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHr5UoRepsEm"
      },
      "outputs": [],
      "source": [
        "tab.to_csv(path_out+name+tab_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_CPz44JpsEn"
      },
      "outputs": [],
      "source": [
        "G_gen3=gen3(num, tri, 0, path_out+name+'GEN3_'+str(num)+suf+'.graphml')\n",
        "nx.write_graphml(G_gen3, path_out+name+'GEN3_'+str(num)+suf+'.graphml')\n",
        "stat=calc_triangles(G_gen3, 1, False)\n",
        "print(stat)\n",
        "x=pd.DataFrame(stat.T, columns=['t1', 't2', 't3', 't4'])\n",
        "x.to_csv(path_out+name+'triGEN3_'+str(num)+suf+'.csv')\n",
        "if not os.path.exists(path_out+name+'GEN3_'+str(num)+suf+'/'):\n",
        "  os.makedirs(path_out+name+'GEN3_'+str(num)+suf+'/')\n",
        "calculate_graph_features(G_gen3, path_out+name+'GEN3_'+str(num)+suf+'/', tab, 'GEN3_'+str(num)+suf+'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhoApWhVpsEn"
      },
      "outputs": [],
      "source": [
        "tab.to_csv(path_out+name+tab_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qajtk0wkrke6"
      },
      "source": [
        "## Centralities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F_sz0FhjL1p"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "tab\n",
        "for num in ['rus', 'en_r1', 'en_r123', 'dutch', 'USF']:\n",
        "  G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  ec=nx.eigenvector_centrality(G, max_iter=10000)\n",
        "  plt.figure(figsize=(8, 6), dpi=200) \n",
        "  plt.title(\"Eigenvector centrality distribution\")\n",
        "  plt.xlabel(\"Centrality\")\n",
        "  plt.ylabel(\"Number of nodes\")\n",
        "  plt.hist(list(ec.values()), bins=100)\n",
        "  plt.savefig(path_out+num+'/ec.png')\n",
        "  plt.close('All')\n",
        "  print(num)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'evc.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-lGNmStjLvw"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus', 'en_r1', 'en_r123', 'dutch', 'USF']:\n",
        "  G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  ec=nx.degree_centrality(G)\n",
        "  plt.figure(figsize=(8, 6), dpi=200) \n",
        "  plt.title(\"Degree centrality distribution\")\n",
        "  plt.xlabel(\"Centrality\")\n",
        "  plt.ylabel(\"Number of nodes\")\n",
        "  plt.hist(list(ec.values()), bins=100)\n",
        "  plt.savefig(path_out+num+'/dc.png')\n",
        "  plt.close('All')\n",
        "  print(num)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'dc.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XPG5TZGk32n"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus', 'en_r1', 'en_r123', 'dutch', 'USF']:\n",
        "  G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  ec=nx.in_degree_centrality(G)\n",
        "  plt.figure(figsize=(8, 6), dpi=200) \n",
        "  plt.title(\"In-degree centrality distribution\")\n",
        "  plt.xlabel(\"Centrality\")\n",
        "  plt.ylabel(\"Number of nodes\")\n",
        "  plt.hist(list(ec.values()), bins=100)\n",
        "  plt.savefig(path_out+num+'/idc.png')\n",
        "  plt.close('All')\n",
        "  print(num)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'idc.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dTnE18zk3zZ"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus', 'en_r1', 'en_r123', 'dutch', 'USF']:\n",
        "  G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  ec=nx.out_degree_centrality(G)\n",
        "  plt.figure(figsize=(8, 6), dpi=200) \n",
        "  plt.title(\"Out-degree centrality distribution\")\n",
        "  plt.xlabel(\"Centrality\")\n",
        "  plt.ylabel(\"Number of nodes\")\n",
        "  plt.hist(list(ec.values()), bins=100)\n",
        "  plt.savefig(path_out+num+'/odc.png')\n",
        "  plt.close('All')\n",
        "  print(num)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'odc.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsGZwxITk3wj"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus', 'en_r1', 'en_r123', 'dutch', 'USF']:\n",
        "  G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  ec=nx.closeness_centrality(G)\n",
        "  plt.figure(figsize=(8, 6), dpi=200) \n",
        "  plt.title(\"Closeness centrality distribution\")\n",
        "  plt.xlabel(\"Centrality\")\n",
        "  plt.ylabel(\"Number of nodes\")\n",
        "  plt.hist(list(ec.values()), bins=100)\n",
        "  plt.savefig(path_out+num+'/cc.png')\n",
        "  plt.close('All')\n",
        "  print(num)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'cc.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym3OjRxxk3uw"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus', 'en_r1', 'en_r123', 'dutch', 'USF']:\n",
        "  G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  ec=nx.betweenness_centrality(G)\n",
        "  plt.figure(figsize=(8, 6), dpi=200) \n",
        "  plt.title(\"Betweenness centrality distribution\")\n",
        "  plt.xlabel(\"Centrality\")\n",
        "  plt.ylabel(\"Number of nodes\")\n",
        "  plt.hist(list(ec.values()), bins=100)\n",
        "  plt.savefig(path_out+num+'/bc.png')\n",
        "  plt.close('All')\n",
        "  print(num)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'bc.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlIUCK_YTxqP"
      },
      "outputs": [],
      "source": [
        "for num in ['rus', 'USF', 'en_r1', 'en_r123', 'dutch']:\n",
        "  # G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  for j in [\"/ER\", \"/GEN\", \"/GEN2\", \"/GEN3\"]:\n",
        "    for k in [\"\", \"_2\", \"_100\", \"_1000\", \"_2000\"]:\n",
        "      name=path_out+num+j+k\n",
        "      if (j==\"/ER\" or num==\"USF\") and k=='_2':\n",
        "        continue\n",
        "      if j=='/GEN' and not k=='':\n",
        "        name=path_out+num+j+'1'+k\n",
        "      if num=='/rus' and not k=='_2' and not j==\"/ER\":\n",
        "        name=name+\"_1\"\n",
        "      G=nx.read_graphml(name+'.graphml')\n",
        "      ec=nx.eigenvector_centrality(G, max_iter=10000)\n",
        "      plt.figure(figsize=(8, 6), dpi=200) \n",
        "      plt.title(\"Eigenvector centrality distribution\")\n",
        "      plt.xlabel(\"Centrality\")\n",
        "      plt.ylabel(\"Number of nodes\")\n",
        "      plt.hist(list(ec.values()), bins=100)\n",
        "      plt.savefig(name+'_ec.png')\n",
        "      plt.close('All')\n",
        "      print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofbt2zDmTxqR"
      },
      "outputs": [],
      "source": [
        "for num in ['rus', 'USF', 'en_r1', 'en_r123', 'dutch']:\n",
        "  # G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  for j in [\"/ER\", \"/GEN\", \"/GEN2\", \"/GEN3\"]:\n",
        "    for k in [\"\", \"_2\", \"_100\", \"_1000\", \"_2000\"]:\n",
        "      name=path_out+num+j+k\n",
        "      if (j==\"/ER\" or num==\"USF\") and k=='_2':\n",
        "        continue\n",
        "      if j=='/GEN' and not k=='':\n",
        "        name=path_out+num+j+'1'+k\n",
        "      if num=='/rus' and not k=='_2' and not j==\"/ER\":\n",
        "        name=name+\"_1\"\n",
        "      G=nx.read_graphml(name+'.graphml')\n",
        "      ec=nx.degree_centrality(G)\n",
        "      plt.figure(figsize=(8, 6), dpi=200) \n",
        "      plt.title(\"Degree centrality distribution\")\n",
        "      plt.xlabel(\"Centrality\")\n",
        "      plt.ylabel(\"Number of nodes\")\n",
        "      plt.hist(list(ec.values()), bins=100)\n",
        "      plt.savefig(name+'_dc.png')\n",
        "      plt.close('All')\n",
        "      print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbgC5egyTxqT"
      },
      "outputs": [],
      "source": [
        "for num in ['rus', 'USF', 'en_r1', 'en_r123', 'dutch']:\n",
        "  # G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  for j in [\"/ER\", \"/GEN\", \"/GEN2\", \"/GEN3\"]:\n",
        "    for k in [\"\", \"_2\", \"_100\", \"_1000\", \"_2000\"]:\n",
        "      name=path_out+num+j+k\n",
        "      if (j==\"/ER\" or num==\"USF\") and k=='_2':\n",
        "        continue\n",
        "      if j=='/GEN' and not k=='':\n",
        "        name=path_out+num+j+'1'+k\n",
        "      if num=='/rus' and not k=='_2' and not j==\"/ER\":\n",
        "        name=name+\"_1\"\n",
        "      G=nx.read_graphml(name+'.graphml')\n",
        "      ec=nx.in_degree_centrality(G)\n",
        "      plt.figure(figsize=(8, 6), dpi=200) \n",
        "      plt.title(\"In-degree centrality distribution\")\n",
        "      plt.xlabel(\"Centrality\")\n",
        "      plt.ylabel(\"Number of nodes\")\n",
        "      plt.hist(list(ec.values()), bins=100)\n",
        "      plt.savefig(name+'_idc.png')\n",
        "      plt.close('All')\n",
        "      print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udXic7jiTxqX"
      },
      "outputs": [],
      "source": [
        "for num in ['rus', 'USF', 'en_r1', 'en_r123', 'dutch']:\n",
        "  # G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  for j in [\"/ER\", \"/GEN\", \"/GEN2\", \"/GEN3\"]:\n",
        "    for k in [\"\", \"_2\", \"_100\", \"_1000\", \"_2000\"]:\n",
        "      name=path_out+num+j+k\n",
        "      if (j==\"/ER\" or num==\"USF\") and k=='_2':\n",
        "        continue\n",
        "      if j=='/GEN' and not k=='':\n",
        "        name=path_out+num+j+'1'+k\n",
        "      if num=='/rus' and not k=='_2' and not j==\"/ER\":\n",
        "        name=name+\"_1\"\n",
        "      G=nx.read_graphml(name+'.graphml')\n",
        "      ec=nx.out_degree_centrality(G)\n",
        "      plt.figure(figsize=(8, 6), dpi=200) \n",
        "      plt.title(\"Out-degree centrality distribution\")\n",
        "      plt.xlabel(\"Centrality\")\n",
        "      plt.ylabel(\"Number of nodes\")\n",
        "      plt.hist(list(ec.values()), bins=100)\n",
        "      plt.savefig(name+'_odc.png')\n",
        "      plt.close('All')\n",
        "      print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdJgbdOGTxqd"
      },
      "outputs": [],
      "source": [
        "for num in ['rus', 'USF', 'en_r1', 'en_r123', 'dutch']:\n",
        "  # G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  for j in [\"/ER\", \"/GEN\", \"/GEN2\", \"/GEN3\"]:\n",
        "    for k in [\"\", \"_2\", \"_100\", \"_1000\", \"_2000\"]:\n",
        "      name=path_out+num+j+k\n",
        "      if (j==\"/ER\" or num==\"USF\") and k=='_2':\n",
        "        continue\n",
        "      if j=='/GEN' and not k=='':\n",
        "        name=path_out+num+j+'1'+k\n",
        "      if num=='/rus' and not k=='_2' and not j==\"/ER\":\n",
        "        name=name+\"_1\"\n",
        "      G=nx.read_graphml(name+'.graphml')\n",
        "      ec=nx.closeness_centrality(G)\n",
        "      plt.figure(figsize=(8, 6), dpi=200) \n",
        "      plt.title(\"Closeness centrality distribution\")\n",
        "      plt.xlabel(\"Centrality\")\n",
        "      plt.ylabel(\"Number of nodes\")\n",
        "      plt.hist(list(ec.values()), bins=100)\n",
        "      plt.savefig(name+'_cc.png')\n",
        "      plt.close('All')\n",
        "      print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epdOSAz1Txqe"
      },
      "outputs": [],
      "source": [
        "for num in ['rus', 'USF', 'en_r1', 'en_r123', 'dutch']:\n",
        "  # G = nx.read_graphml(path_out+num+\"_main.graphml\")\n",
        "  for j in [\"/ER\", \"/GEN\", \"/GEN2\", \"/GEN3\"]:\n",
        "    for k in [\"\", \"_2\", \"_100\", \"_1000\", \"_2000\"]:\n",
        "      name=path_out+num+j+k\n",
        "      if (j==\"/ER\" or num==\"USF\") and k=='_2':\n",
        "        continue\n",
        "      if j=='/GEN' and not k=='':\n",
        "        name=path_out+num+j+'1'+k\n",
        "      if num=='/rus' and not k=='_2' and not j==\"/ER\":\n",
        "        name=name+\"_1\"\n",
        "      G=nx.read_graphml(name+'.graphml')\n",
        "      ec=nx.betweenness_centrality(G)\n",
        "      plt.figure(figsize=(8, 6), dpi=200) \n",
        "      plt.title(\"Betweenness centrality distribution\")\n",
        "      plt.xlabel(\"Centrality\")\n",
        "      plt.ylabel(\"Number of nodes\")\n",
        "      plt.hist(list(ec.values()), bins=100)\n",
        "      plt.savefig(name+'_bc.png')\n",
        "      plt.close('All')\n",
        "      print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4_xy5XfZoGm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT8VCLP1ZpAM"
      },
      "source": [
        "## DL & BH pictures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOlYGeipdbKy"
      },
      "outputs": [],
      "source": [
        "G_gen2 = nx.read_graphml(path_out+name+\"GEN2_2.graphml\")\n",
        "G_gen3 = nx.read_graphml(path_out+name+\"GEN3_2.graphml\")\n",
        "G_ER = nx.read_graphml(path_out+name+\"ER.graphml\")\n",
        "G_gen = nx.read_graphml(path_out+name+\"GEN1_2.graphml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4uOtWkwyqqO"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(path_out+name+'gen1_2DL/'):\n",
        "  os.makedirs(path_out+name+'gen1_2DL/')\n",
        "DL_2(G_gen, G, 'gen1_2DL/')\n",
        "if not os.path.exists(path_out+name+'gen2_2DL/'):\n",
        "  os.makedirs(path_out+name+'gen2_2DL/')\n",
        "DL_2(G_gen2.subgraph(max(nx.strongly_connected_components(G_gen2), key=len)), G, 'gen2_2DL/')\n",
        "if not os.path.exists(path_out+name+'gen3_2DL/'):\n",
        "  os.makedirs(path_out+name+'gen3_2DL/')\n",
        "# DL(G_gen3, 'gen3_DL/')\n",
        "DL_2(G_gen3.subgraph(max(nx.strongly_connected_components(G_gen3), key=len)), G, 'gen3_DL/')\n",
        "if not os.path.exists(path_out+name+'ER_DL/'):\n",
        "  os.makedirs(path_out+name+'ER_DL/')\n",
        "DL_2(G_ER, G, 'ER_DL/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "scHFcnQYZpAP"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(path_out+name+'gen1_2BH/'):\n",
        "  os.makedirs(path_out+name+'gen1_2BH/')\n",
        "BH(G_gen, G, 'gen1_2BH/')\n",
        "if not os.path.exists(path_out+name+'gen2_2BH/'):\n",
        "  os.makedirs(path_out+name+'gen2_2BH/')\n",
        "BH(G_gen2.subgraph(max(nx.strongly_connected_components(G_gen2), key=len)), G, 'gen2_2BH/')\n",
        "if not os.path.exists(path_out+name+'gen3_2BH/'):\n",
        "  os.makedirs(path_out+name+'gen3_2BH/')\n",
        "BH(G_gen3.subgraph(max(nx.strongly_connected_components(G_gen3), key=len)), G, 'gen3_2BH/')\n",
        "if not os.path.exists(path_out+name+'ER_BH/'):\n",
        "  os.makedirs(path_out+name+'ER_BH/')\n",
        "BH(G_ER, G, 'ER_BH/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YWoAQOJllar"
      },
      "outputs": [],
      "source": [
        "name='USF/SB_4845_3_base500'\n",
        "G = nx.read_graphml(path_out+name+\".graphml\")\n",
        "# name=name+'GEN1_2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0E8jnm3c1Io"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(path_out+name+'/DL2/'):\n",
        "  os.makedirs(path_out+name+'/DL2/')\n",
        "A=nx.to_scipy_sparse_array(G)\n",
        "B=(A.T/A.sum(1)).T\n",
        "B[B==np.inf]=0\n",
        "B[np.isnan(B)]=0\n",
        "e = scipy.sparse.linalg.eigs(B, k=A.shape[0], which='LR', return_eigenvectors=False)\n",
        "plt.figure(figsize = (10, 10), dpi=200)\n",
        "plt.scatter(e.real, e.imag)\n",
        "plt.xlim(-1,1)\n",
        "plt.ylim(-1,1)\n",
        "# plt.axis('off')\n",
        "plt.show()\n",
        "plt.savefig(path_out+name+'/DL2/'+'vals.jpeg')\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lisdsn5qKx3G"
      },
      "source": [
        "## NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VGGPRQsKx3H"
      },
      "outputs": [],
      "source": [
        "which='USF_main'\n",
        "name='USF/SB_2000_2_base200'\n",
        "G = nx.read_graphml(path_out+name+\".graphml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNodgMWGHWmD"
      },
      "outputs": [],
      "source": [
        "!rm -r el_lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWrhYpw_Hkjn"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(path_out+name+'/NB2/'):\n",
        "  os.makedirs(path_out+name+'/NB2/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUdHp2-hMKx1"
      },
      "outputs": [],
      "source": [
        "G=nx.convert_node_labels_to_integers(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsOKaipkKx3I"
      },
      "outputs": [],
      "source": [
        "NB(G, save_to=path_out+name+'/NB2/', num=3000, dir=True, LM=True)\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xstZPRabKx3J"
      },
      "outputs": [],
      "source": [
        "shutil.copytree(path_in+'el_lib', 'el_lib')\n",
        "from el_lib import Alpha\n",
        "pipeline_object = Alpha(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1RTRC0LKx3J"
      },
      "outputs": [],
      "source": [
        "adj_sym=nx.to_numpy_array(G, weight=None) #non-symmetrized\n",
        "graph_sym = nx.from_numpy_array(adj_sym, create_using=nx.DiGraph)\n",
        "all_edg_sym = np.array(graph_sym.edges())\n",
        "A=scipy.sparse.load_npz(path_out+name+'NB2/NB_A.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tAOrLwrKx3J"
      },
      "outputs": [],
      "source": [
        "#symmetrized\n",
        "adj = pipeline_object.adjacency_mat()\n",
        "_, adj_sym = pipeline_object.preprocessing_matrix(adj)\n",
        "all_edg_sym = pipeline_object.edges_extracting(adj_sym)\n",
        "A=scipy.sparse.load_npz(path_out+name+'NB/NB_A.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-dlwQAFKx3K"
      },
      "outputs": [],
      "source": [
        "vals_flow, vecs =  scipy.sparse.linalg.eigs(A, k = 40,  which='LR', return_eigenvectors=True)\n",
        "tail=True\n",
        "degrees = np.sum(adj_sym, axis=1)\n",
        "cr_rad = np.sqrt(np.mean(np.array(degrees)/(np.array([x-1 if x>1 else x for x in degrees])))/(np.mean(degrees)))\n",
        "if tail == True: \n",
        "    eig_vals = vals_flow[vals_flow > cr_rad]\n",
        "order = np.argsort(-np.abs(np.array(eig_vals)))\n",
        "\n",
        "vecs = vecs[:,order[1:]]\n",
        "vals = np.array(eig_vals)[order[1:]] \n",
        "\n",
        "len_of_tail = np.shape(vals)[0]\n",
        "\n",
        "translated_eig_vec = np.zeros((np.shape(adj_sym)[0],len(vals)))\n",
        "for i in range(len(all_edg_sym)):\n",
        "    for k in range(len(vals)):\n",
        "        translated_eig_vec[all_edg_sym[i][0],k] += vecs[i,k]\n",
        "cr_rad, len_of_tail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfm7tOinKx3K"
      },
      "outputs": [],
      "source": [
        "colours = np.zeros((np.shape(translated_eig_vec)[1], np.shape(translated_eig_vec)[0]))\n",
        "\n",
        "for i in np.arange(1, np.shape(translated_eig_vec)[1]+1):\n",
        "    print(i, end=' ')\n",
        "    if np.shape(translated_eig_vec)[1] != 0:\n",
        "    \n",
        "        cluster = KMeans(n_clusters=i+1, n_init=50, max_iter = 5000)\n",
        "        cluster.fit(translated_eig_vec[:,:i+1])\n",
        "        cluster = pipeline_object.sorted_cluster(translated_eig_vec[:, :i+1], cluster)\n",
        "        colours[i-1,:] = cluster.labels_\n",
        "      \n",
        "    else:  \n",
        "        colours[i-1,:] = [0] * np.shape(translated_eig_vec)[0] \n",
        "    if not i%5 or i==np.shape(translated_eig_vec)[1]:\n",
        "      print('\\n', i-5+1, i+1)\n",
        "      c_in, c_out, w_in, w_out, c, optimal_clusters = pipeline_object.cluster_limit(colours[i-5:i], adj_sym)\n",
        "      for j in range(np.shape(optimal_clusters)[0]):\n",
        "        print((i-5+j+2))\n",
        "        if optimal_clusters[j,0] > optimal_clusters[j,1]/(j+2)*(i-5+j+2):\n",
        "            print(f'Number of clusters {int(optimal_clusters[j,2])+i-5}: {round(optimal_clusters[j,0],3)} > {round(optimal_clusters[j,1]/(j+2)*(i-5+j+2),3)}')\n",
        "        else:\n",
        "            print(f'Number of clusters {int(optimal_clusters[j,2])+i-5}: {round(optimal_clusters[j,0],3)} < {round(optimal_clusters[j,1]/(j+2)*(i-5+j+2),3)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2XJC6SXKx3K"
      },
      "outputs": [],
      "source": [
        "c=7\n",
        "cluster = KMeans(n_clusters=c, n_init=100, max_iter = 10000)\n",
        "cluster.fit(translated_eig_vec[:, :c])\n",
        "cluster = pipeline_object.sorted_cluster(translated_eig_vec, cluster)\n",
        "cl_best= cluster.labels_\n",
        "ns=list(G.nodes)\n",
        "k_best=c\n",
        "for i in range(len(G)):\n",
        "    G.nodes[ns[i]]['clust']=cl_best[i]\n",
        "for i in range(k_best):\n",
        "    clust=np.where(cl_best==i)[0]\n",
        "    nodes=[ns[j] for j in clust]\n",
        "    print('\\n\\n', i, len(clust))\n",
        "    if len(clust)<500:\n",
        "        for p in nodes:\n",
        "            print(G.nodes()[p]['name'], end=', ')\n",
        "nx.write_graphml(G, path_out+name+'NB/clustered.graphml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk-xRunBKx3L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3193GKyvwC3"
      },
      "source": [
        "## DL & BH clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSzOiBsN94La"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(path_out+name):\n",
        "  os.makedirs(path_out+name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUhKW-JX_VtR"
      },
      "outputs": [],
      "source": [
        "mk=300\n",
        "which='BH'\n",
        "E=BH(G)[:, 1:]\n",
        "mk=E.shape[1] if which==\"BH\" else mk\n",
        "ns=list(G.nodes)\n",
        "st=mk\n",
        "n=len(G)\n",
        "ed=G.number_of_edges()\n",
        "M=nx.directed_modularity_matrix(G)\n",
        "mod_top=-2\n",
        "flag=0\n",
        "for k in range(st, mk+1):\n",
        "  if k<2:\n",
        "    break\n",
        "  print('\\n\\n', k)\n",
        "  emb=((E.T)[:k]).T\n",
        "  cl=spectral_clustering(emb, k)\n",
        "  I=np.zeros((n, n))\n",
        "  for i in range(n):\n",
        "    for j in range(i, n):\n",
        "      I[i][j]=I[j][i]=int(cl[i]==cl[j])\n",
        "  mod=(M*I).sum()/ed\n",
        "  if mod>mod_top:\n",
        "    mod_top=mod\n",
        "    print(mod, '-- new best modularity')\n",
        "    flag=1\n",
        "    cl_best=cl\n",
        "    k_best=k\n",
        "  if flag and not k%5 or st==mk:\n",
        "    flag=0\n",
        "    print(k_best)\n",
        "    for i in range(len(G)):\n",
        "        G.nodes[ns[i]]['clust']=cl_best[i]\n",
        "    if not os.path.exists(path_out+name+which+'/'+str(k_best)+'/'):\n",
        "        os.makedirs(path_out+name+which+'/'+str(k_best)+'/')\n",
        "    nx.write_graphml(G, path_out+name+which+'/'+str(k_best)+'/clustered.graphml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD-nb0RCvU5h"
      },
      "source": [
        "## NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly-ewGYS5W0q"
      },
      "outputs": [],
      "source": [
        "which='USF_main'\n",
        "name='USF/'\n",
        "G = nx.read_graphml(path_out+\"graphs/\"+which+\".graphml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRPYbiME8GBj"
      },
      "outputs": [],
      "source": [
        "NB(G, save_to=path_out+name+'NB2/', dir=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYCGyMRn76wk"
      },
      "outputs": [],
      "source": [
        "shutil.copytree(path_in+'el-lib', 'el_lib')\n",
        "from el_lib import Alpha\n",
        "pipeline_object = Alpha(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbbL9ubL5zR4"
      },
      "outputs": [],
      "source": [
        "adj_sym=nx.to_numpy_array(G, weight=None) #non-symmetrized\n",
        "graph_sym = nx.from_numpy_array(adj_sym, create_using=nx.DiGraph)\n",
        "all_edg_sym = np.array(graph_sym.edges())\n",
        "A=scipy.sparse.load_npz(path_out+name+'NB2/NB_A.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIlVSgea5zNE"
      },
      "outputs": [],
      "source": [
        "#symmetrized\n",
        "adj = pipeline_object.adjacency_mat()\n",
        "_, adj_sym = pipeline_object.preprocessing_matrix(adj)\n",
        "all_edg_sym = pipeline_object.edges_extracting(adj_sym)\n",
        "A=scipy.sparse.load_npz(path_out+name+'NB/NB_A.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvazi6lJ5zJz"
      },
      "outputs": [],
      "source": [
        "vals_flow, vecs =  scipy.sparse.linalg.eigs(A, k = 40,  which='LR', return_eigenvectors=True)\n",
        "tail=True\n",
        "degrees = np.sum(adj_sym, axis=1)\n",
        "cr_rad = np.sqrt(np.mean(np.array(degrees)/(np.array([x-1 if x>1 else x for x in degrees])))/(np.mean(degrees)))\n",
        "if tail == True: \n",
        "    eig_vals = vals_flow[vals_flow > cr_rad]\n",
        "order = np.argsort(-np.abs(np.array(eig_vals)))\n",
        "\n",
        "vecs = vecs[:,order[1:]]\n",
        "vals = np.array(eig_vals)[order[1:]] \n",
        "\n",
        "len_of_tail = np.shape(vals)[0]\n",
        "\n",
        "translated_eig_vec = np.zeros((np.shape(adj_sym)[0],len(vals)))\n",
        "for i in range(len(all_edg_sym)):\n",
        "    for k in range(len(vals)):\n",
        "        translated_eig_vec[all_edg_sym[i][0],k] += vecs[i,k]\n",
        "cr_rad, len_of_tail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJgboqkovXoc"
      },
      "outputs": [],
      "source": [
        "colours = np.zeros((np.shape(translated_eig_vec)[1], np.shape(translated_eig_vec)[0]))\n",
        "\n",
        "for i in np.arange(1, np.shape(translated_eig_vec)[1]+1):\n",
        "    print(i, end=' ')\n",
        "    if np.shape(translated_eig_vec)[1] != 0:\n",
        "    \n",
        "        cluster = KMeans(n_clusters=i+1, n_init=50, max_iter = 5000)\n",
        "        cluster.fit(translated_eig_vec[:,:i+1])\n",
        "        cluster = pipeline_object.sorted_cluster(translated_eig_vec[:, :i+1], cluster)\n",
        "        colours[i-1,:] = cluster.labels_\n",
        "      \n",
        "    else:  \n",
        "        colours[i-1,:] = [0] * np.shape(translated_eig_vec)[0] \n",
        "    if not i%5 or i==np.shape(translated_eig_vec)[1]:\n",
        "      print('\\n', i-5+1, i+1)\n",
        "      c_in, c_out, w_in, w_out, c, optimal_clusters = pipeline_object.cluster_limit(colours[i-5:i], adj_sym)\n",
        "      for j in range(np.shape(optimal_clusters)[0]):\n",
        "        print((i-5+j+2))\n",
        "        if optimal_clusters[j,0] > optimal_clusters[j,1]/(j+2)*(i-5+j+2):\n",
        "            print(f'Number of clusters {int(optimal_clusters[j,2])+i-5}: {round(optimal_clusters[j,0],3)} > {round(optimal_clusters[j,1]/(j+2)*(i-5+j+2),3)}')\n",
        "        else:\n",
        "            print(f'Number of clusters {int(optimal_clusters[j,2])+i-5}: {round(optimal_clusters[j,0],3)} < {round(optimal_clusters[j,1]/(j+2)*(i-5+j+2),3)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E3MpjI162Ns"
      },
      "outputs": [],
      "source": [
        "c=7\n",
        "cluster = KMeans(n_clusters=c, n_init=100, max_iter = 10000)\n",
        "cluster.fit(translated_eig_vec[:, :c])\n",
        "cluster = pipeline_object.sorted_cluster(translated_eig_vec, cluster)\n",
        "cl_best= cluster.labels_\n",
        "ns=list(G.nodes)\n",
        "k_best=c\n",
        "for i in range(len(G)):\n",
        "    G.nodes[ns[i]]['clust']=cl_best[i]\n",
        "for i in range(k_best):\n",
        "    clust=np.where(cl_best==i)[0]\n",
        "    nodes=[ns[j] for j in clust]\n",
        "    print('\\n\\n', i, len(clust))\n",
        "    if len(clust)<500:\n",
        "        for p in nodes:\n",
        "            print(G.nodes()[p]['name'], end=', ')\n",
        "nx.write_graphml(G, path_out+name+'NB/clustered.graphml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyZwzcdxvaG_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTP-XoKhLkYJ"
      },
      "source": [
        "## Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYhtMlKyusRU"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"USF/DL/269/clustered.graphml\") #!load only one that needed ignoring others\n",
        "name='USF/DL/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQQacAEugUWH"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"dutch/DL/31/clustered.graphml\")\n",
        "name='dutch/DL/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-I90sqMhGbf"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"en_r1/DL/53/clustered.graphml\")\n",
        "name='en_r1/DL/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1f2C5LGhGT9"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"en_r123/DL/22/clustered.graphml\")\n",
        "name='en_r123/DL/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP63qkjchGLf"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"rus/DL/21/clustered.graphml\")\n",
        "name='rus/DL/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_ZTGTzFTX0d"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"rus/BHr+/18/clustered.graphml\")\n",
        "name='rus/BHr+/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsjdA55qZW-j"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"en_r123/NB/clustered.graphml\")\n",
        "name='en_r123/NB/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOIH303nZDPE"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"dutch/NB/clustered.graphml\")\n",
        "name='dutch/NB/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-MusZukhsO8"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"USF/NB2/clustered.graphml\")\n",
        "name='USF/NB2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwksXO6ZhsLe"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"rus/NB2/clustered.graphml\")\n",
        "name='rus/NB2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbRMB-lahsIB"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"en_r1/NB2/clustered.graphml\")\n",
        "name='en_r1/NB2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpZYw5-Rt088"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"en_r123/NB2/clustered.graphml\")\n",
        "name='en_r123/NB2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVpfI24Ot0yl"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(path_out+\"dutch/NB2/clustered.graphml\")\n",
        "name='dutch/NB2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJkqucKcutW0"
      },
      "outputs": [],
      "source": [
        "cl_best=np.array([G.nodes[i]['clust'] for i in G.nodes()])\n",
        "mk=len(set(cl_best))\n",
        "cl_A=np.zeros((mk, mk))\n",
        "cl_nn=np.zeros(mk)\n",
        "ns=list(G.nodes)\n",
        "for i in G.nodes:\n",
        "  for j in G.nodes:\n",
        "    if (i, j) in G.edges():\n",
        "      cl_A[G.nodes[i]['clust']][G.nodes[j]['clust']]+=1\n",
        "cl_nn=[len(np.where(cl_best==i)[0]) for i in range(mk)]\n",
        "for i in range(mk):\n",
        "  for j in range(mk):\n",
        "    l=cl_nn[i]*cl_nn[j]\n",
        "    if i==j:\n",
        "      l=cl_nn[i]*(cl_nn[j]-1)\n",
        "    if not l==0:\n",
        "      cl_A[i][j]/=l\n",
        "    # if i==j and cl_A[i][j]==0 and l==0:\n",
        "    #   cl_A[i][j]=1\n",
        "G_cl=nx.DiGraph(cl_A-np.diag(np.diagonal(cl_A)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oehRwnxHAokP"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CynGlAjgE062"
      },
      "outputs": [],
      "source": [
        "name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFwJMEI1_7qV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12),dpi=200)\n",
        "r=sns.heatmap(cl_A)\n",
        "plt.title(\"Clustering density matrix\")\n",
        "plt.savefig(path_out+name+'matr.png')\n",
        "plt.show()\n",
        "plt.close('All')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUfytbXc6w6V"
      },
      "outputs": [],
      "source": [
        "ed=G.number_of_edges()\n",
        "M=nx.directed_modularity_matrix(G)\n",
        "cl=[G.nodes()[i]['clust'] for i in G.nodes()]\n",
        "n=len(G)\n",
        "I=np.zeros((n, n))\n",
        "for i in range(n):\n",
        "  for j in range(i, n):\n",
        "    I[i][j]=I[j][i]=int(cl[i]==cl[j])\n",
        "mod=(M*I).sum()/ed\n",
        "mod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5j62pk8rBMJ"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "num='USF/DL/269/'\n",
        "num2='USF/NB2/'\n",
        "G = nx.read_graphml(path_out+num+\"clustered.graphml\") \n",
        "G2 = nx.read_graphml(path_out+num2+\"clustered.graphml\")\n",
        "print(num, num2)\n",
        "print(G.nodes(), '\\n', G2.nodes())\n",
        "# cor=list(enumerate(G2.nodes()))\n",
        "cor=[(int(i), G2.nodes()[i]['name']) for i in G2.nodes()]\n",
        "l1=[G2.nodes()[i]['clust'] for i in G2.nodes()]\n",
        "l2=[G.nodes()[i]['clust'] for _, i in cor]\n",
        "sc=sklearn.metrics.normalized_mutual_info_score(l1, l2)\n",
        "ar=sklearn.metrics.adjusted_rand_score(l1, l2)\n",
        "sc, ar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqTKjaucrKFc"
      },
      "outputs": [],
      "source": [
        "\n",
        "cor=[(int(i), G2.nodes()[i]['name']) for i in G2.nodes()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haMcd1FNutZi"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=['nn', 'ne', 'diameter', 'radius', 'ASPL', 'transitivity', 'ACC', 'GCN', 'Density', 'Degree mean',\n",
        "                          'Degree var', 'In-degree mean', 'In-degree var', 'Out-degree mean', 'Out-degree var',\n",
        "                          'gamma', 'k_min', 'AII', 'AOO', \"AIO\", 'AOI', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-NHeXR9utUD"
      },
      "outputs": [],
      "source": [
        "for i in range(mk):\n",
        "  if not os.path.exists(path_out+name+str(mk)+'/'+str(i)+'/'):\n",
        "      os.makedirs(path_out+name+str(mk)+'/'+str(i)+'/')\n",
        "  clust=np.where(cl_best==i)[0]\n",
        "  nodes=[ns[j] for j in clust]\n",
        "  print('\\n\\n', i, len(clust))\n",
        "  sub=G.subgraph(nodes)\n",
        "  if len(clust)>1:\n",
        "    calculate_graph_features(sub, path_out+name+str(mk)+'/'+str(i)+'/', tab, i)\n",
        "  else:\n",
        "    tab.loc[i]=[None for i in range(31)]\n",
        "    tab.loc[i, 'nn']=1\n",
        "    tab.loc[i, 0]=nodes[0]\n",
        "tab.to_csv(path_out+name+'tab.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY8lr_0sbfOy"
      },
      "outputs": [],
      "source": [
        "tab=pd.read_csv(path_out+name+'tab.csv') #fill names manually\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8pXCByVNLiL"
      },
      "outputs": [],
      "source": [
        "lay= nx.spring_layout(G_cl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dod3LK5nbzdY"
      },
      "outputs": [],
      "source": [
        "# with open(path_out+name+'la.json') as f: #only if outer-made layout is present\n",
        "#   lay={int(i['id']): np.array((i['x'], i['y'])) for i in json.load(f)['nodes']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi8df2CeTF_t"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-KxKvN4HH2U"
      },
      "outputs": [],
      "source": [
        "for i in G_cl.nodes: #if names not entered manually change 'name' -> '0'\n",
        "  G_cl.nodes[i]['name']=tab.loc[i]['name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Hnr2flTF9l"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40, 40), dpi=200)\n",
        "ec=nx.eigenvector_centrality(G_cl, max_iter=10000)\n",
        "last=sorted(ec.values())[-max(min(len(G_cl)//2, 70), min(len(G_cl), 70))]\n",
        "pos=lay\n",
        "nx.draw_networkx_nodes(G_cl, pos, node_size=[i*50*3.7**(i*15)+20 for i in ec.values()], alpha=0.85,  node_color=[i for i in ec.values()], cmap=plt.cm.Oranges)\n",
        "nx.draw_networkx_edges(G_cl, pos, alpha=[1 for i in nx.get_edge_attributes(G_cl, 'weight').values()])\n",
        "for params in labels_list_parameters1(G_cl, pos, ec, 100, last, True):\n",
        "    nx.draw_networkx_labels(**params)\n",
        "plt.savefig(path_out+name+'/eig_layout2.jpeg')\n",
        "plt.show()\n",
        "plt.close('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkXX16dx0RQn"
      },
      "outputs": [],
      "source": [
        "nds=np.array(cl_nn)\n",
        "nds1=np.diagonal(cl_A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdQe23OQsB81"
      },
      "outputs": [],
      "source": [
        "nds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MghSH4uVTF5J"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40, 40), dpi=200)\n",
        "last=sorted(nds/nds.max())[-max(min(len(G_cl)//2, 70), min(len(G_cl), 70))]\n",
        "# pos = nx.spring_layout(G_cl)\n",
        "pos=lay\n",
        "nx.draw_networkx_nodes(G_cl, pos, node_size=[i*20 for i in nds], alpha=0.85,  node_color=[i for i in nds1], cmap=plt.cm.Oranges)\n",
        "nx.draw_networkx_edges(G_cl, pos, alpha=[i*10 for i in nx.get_edge_attributes(G_cl, 'weight').values()])\n",
        "for params in labels_list_parameters1(G_cl, pos,  [max(i, 0.5) for i in nds/nds.max()], 70, last, True):\n",
        "    nx.draw_networkx_labels(**params)\n",
        "plt.savefig(path_out+name+'dens_layout2.png')\n",
        "plt.show()\n",
        "plt.close('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrD0Vphj0zil"
      },
      "outputs": [],
      "source": [
        "nx.write_graphml(G_cl, path_out+name+'cluster_graph.graphml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu7-heDjxLkw"
      },
      "source": [
        "## Clusters centralities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPabRxylLWW9"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "\n",
        "  ec=nx.eigenvector_centrality(G, max_iter=10000)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'evc_cl2.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj2OIBOUMjBm"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus/DL/', 'en_r1/DL/', 'en_r123/DL/', 'dutch/DL/', 'USF/DL/', 'rus/BHr+/'\n",
        "            'rus/NB2/', 'en_r1/NB2/', 'en_r123/NB2/', 'dutch/NB2/', 'USF/NB2/', 'en_r123/NB/', 'dutch/NB/',]:\n",
        "  G = nx.read_graphml(path_out+num+\"cluster_graph.graphml\")\n",
        "  ec=nx.degree_centrality(G)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'dc_cl2.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jyt6EjUMi7t"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus/DL/', 'en_r1/DL/', 'en_r123/DL/', 'dutch/DL/', 'USF/DL/', 'rus/BHr+/'\n",
        "            'rus/NB2/', 'en_r1/NB2/', 'en_r123/NB2/', 'dutch/NB2/', 'USF/NB2/', 'en_r123/NB/', 'dutch/NB/',]:\n",
        "  G = nx.read_graphml(path_out+num+\"cluster_graph.graphml\")\n",
        "  ec=nx.in_degree_centrality(G)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'idc_cl2.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMuOEjY3Mi2i"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus/DL/', 'en_r1/DL/', 'en_r123/DL/', 'dutch/DL/', 'USF/DL/', 'rus/BHr+/'\n",
        "            'rus/NB2/', 'en_r1/NB2/', 'en_r123/NB2/', 'dutch/NB2/', 'USF/NB2/', 'en_r123/NB/', 'dutch/NB/',]:\n",
        "  G = nx.read_graphml(path_out+num+\"cluster_graph.graphml\")\n",
        "  ec=nx.out_degree_centrality(G)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'odc_cl2.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dw__BdGMiwi"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus/DL/', 'en_r1/DL/', 'en_r123/DL/', 'dutch/DL/', 'USF/DL/', 'rus/BHr+/'\n",
        "            'rus/NB2/', 'en_r1/NB2/', 'en_r123/NB2/', 'dutch/NB2/', 'USF/NB2/', 'en_r123/NB/', 'dutch/NB/',]:\n",
        "  G = nx.read_graphml(path_out+num+\"cluster_graph.graphml\")\n",
        "  ec=nx.closeness_centrality(G)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'cc_cl2.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo-KsSbRMikI"
      },
      "outputs": [],
      "source": [
        "tab=pd.DataFrame(columns=[i for i in range(15)])\n",
        "for num in ['rus/DL/', 'en_r1/DL/', 'en_r123/DL/', 'dutch/DL/', 'USF/DL/', 'rus/BHr+/'\n",
        "            'rus/NB2/', 'en_r1/NB2/', 'en_r123/NB2/', 'dutch/NB2/', 'USF/NB2/', 'en_r123/NB/', 'dutch/NB/',]:\n",
        "  G = nx.read_graphml(path_out+num+\"cluster_graph.graphml\")\n",
        "  ec=nx.betweenness_centrality(G)\n",
        "  for m, j in enumerate(sorted(ec, key=ec.get, reverse=True)[:15]):\n",
        "    print(G.nodes()[j]['name'], ' -- ', round(ec[j], 4), end=', ')\n",
        "    tab.loc[num, m]=G.nodes()[j]['name']\n",
        "  print()\n",
        "tab.to_csv(path_out+'bc_cl2.csv')\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj_oBoDpzRtm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQKe-3jldPvC"
      },
      "source": [
        "## Homology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ5UcQbU6jOL"
      },
      "outputs": [],
      "source": [
        "name='USF/SB_4845_0_base0'\n",
        "G = nx.read_graphml(path_out+name+\".graphml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbVG7hDZvQG5"
      },
      "outputs": [],
      "source": [
        "A=nx.to_numpy_array(G)\n",
        "A=A-np.diag(np.diagonal(A))\n",
        "A=scipy.sparse.csr_matrix(A)\n",
        "A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xghD-1lzSTM"
      },
      "outputs": [],
      "source": [
        "del G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_TN885DvQDg"
      },
      "outputs": [],
      "source": [
        "res1=pyflagser.flagser_unweighted(A)\n",
        "# res=res1['dgms']\n",
        "print(name, res1['betti'], res1['cell_count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLBhvFpgvDN6"
      },
      "outputs": [],
      "source": [
        "a='USF/SB_'\n",
        "b='_base'\n",
        "last=4845\n",
        "for i in [last]:\n",
        "    for j in [0, 1, 2, 3]:\n",
        "        for k in [0, 100, 200, 500]:\n",
        "            name=a+str(i)+'_'+str(j)+b+str(k)\n",
        "            if not os.path.exists(path_out+name+'.graphml'):\n",
        "                print(name, 'not found')\n",
        "                continue\n",
        "            G = nx.read_graphml(path_out+name+\".graphml\")\n",
        "            A=nx.to_numpy_array(G)\n",
        "            A=A-np.diag(np.diagonal(A))\n",
        "            A=scipy.sparse.csr_matrix(A)\n",
        "            res1=pyflagser.flagser_unweighted(A)\n",
        "            print(name, 'betti', res1['betti'], 'cells', res1['cell_count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOLJYaPn2c0Y"
      },
      "outputs": [],
      "source": [
        "name='USF/'\n",
        "G = nx.read_graphml(path_out+name+\"USF_main.graphml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UN_UgdPw0mD"
      },
      "outputs": [],
      "source": [
        "A=nx.to_numpy_array(G)\n",
        "A=A-np.diag(np.diagonal(A))\n",
        "A=scipy.sparse.csr_matrix(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gSKyW0lqEy3"
      },
      "outputs": [],
      "source": [
        "del G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSFvZg3q2ZcA"
      },
      "outputs": [],
      "source": [
        "res2=pyflagser.flagser_weighted(A)['dgms']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwEF7vi0RuUK"
      },
      "outputs": [],
      "source": [
        "# res2=np.load(path_out+'en_r123/PH/PH.npy', allow_pickle=True)[()]['dgms']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vddpDvu1R5NW"
      },
      "outputs": [],
      "source": [
        "for i in range(0, min(len(res), len(res2))):\n",
        "  print(i, len(res[i]), len(res2[i]))\n",
        "  bn=0\n",
        "  res[i][res[i]==np.inf]=1\n",
        "  res2[i][res2[i]==np.inf]=1\n",
        "  k=0\n",
        "  for x, y in res[i]:\n",
        "    k+=1\n",
        "    if not k% (max(len(res[i])//10, 1)):\n",
        "      print(k, end=' ')\n",
        "    best=1\n",
        "    for x1, y1 in res2[i]:\n",
        "      dst=max(abs(x-x1), abs(y-y1))\n",
        "      if dst<bn:\n",
        "        continue\n",
        "      if dst<best: \n",
        "        best=dst\n",
        "    if best>bn:\n",
        "      bn=best\n",
        "    if bn==1:\n",
        "      break\n",
        "  if bn==1:\n",
        "    continue\n",
        "  print()\n",
        "  k=0\n",
        "  for x, y in res2[i]:\n",
        "    k+=1\n",
        "    if not k% (max(len(res2[i])//10, 1)):\n",
        "      print(k, end=' ')\n",
        "    best=1\n",
        "    for x1, y1 in res[i]:\n",
        "      dst=max(abs(x-x1), abs(y-y1))\n",
        "      if dst<best: \n",
        "        best=dst\n",
        "    if best>bn:\n",
        "      bn=best\n",
        "    if bn==1:\n",
        "      break\n",
        "  print(bn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tinWcRRvfHRn"
      },
      "outputs": [],
      "source": [
        "# res=np.load(path_out+'en_r123/PH/PH.npy', allow_pickle=True)[()]\n",
        "# res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QRbUR9TrwBe"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(path_out+name+'PH/'):\n",
        "  os.makedirs(path_out+name+'PH/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBZjgV5TvQAi"
      },
      "outputs": [],
      "source": [
        "for dim in range(len(res)-1):\n",
        "  plt.figure(figsize=(8, 6), dpi=200)\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  x=res['dgms'][dim][:, 0]\n",
        "  y=res['dgms'][dim][:, 1]\n",
        "  y[y==np.inf]=1\n",
        "  print(len(x))\n",
        "  plt.scatter(x, y, s=5)\n",
        "  plt.plot([0,1], [0,1],  c='k', alpha=0.2);\n",
        "  plt.xlabel('birth')\n",
        "  plt.ylabel('death')\n",
        "  plt.title('Persistence diagram dim='+str(dim))\n",
        "  plt.savefig(path_out+name+'PH/PD'+str(dim)+'.jpeg')\n",
        "  plt.close('All')\n",
        "  if len(x)<500000:\n",
        "    plt.figure(figsize=(8, 6), dpi=200)\n",
        "    pos=[i for i in range(x.shape[0])]\n",
        "    plt.barh(pos, y-x,  left=x)\n",
        "    # plt.setxticks(None)\n",
        "    plt.title('Persistence barcode dim='+str(dim))\n",
        "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
        "    plt.xticks([i for i in np.arange(0, 1.1, 0.1)])\n",
        "    plt.show()\n",
        "    plt.savefig(path_out+name+'PH/PB'+str(dim)+'.jpeg')\n",
        "    plt.close('All')\n",
        "  # plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAhzEH-DvP9o"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6), dpi=200)\n",
        "plt.title('Persistence diagram')\n",
        "for dim in range(len(res['betti'])-1):\n",
        "  plt.rcParams['font.size'] = '14'\n",
        "  x=res['dgms'][dim][:, 0]\n",
        "  y=res['dgms'][dim][:, 1]\n",
        "  y[y==np.inf]=1\n",
        "  print(len(x))\n",
        "  plt.scatter(x, y, s=5, label='dim '+str(dim))\n",
        "  plt.plot([0,1], [0,1],  c='k', alpha=0.2);\n",
        "  plt.xlabel('birth')\n",
        "  plt.ylabel('death')\n",
        "  # plt.close('All')\n",
        "  \n",
        "  # plt.figure(figsize=(8, 6), dpi=200)\n",
        "  # x=res['dgms'][dim][:, 0]\n",
        "  # y=res['dgms'][dim][:, 1]\n",
        "  # y[y==np.inf]=1\n",
        "  # plt.scatter(x, y, s=5)\n",
        "  # plt.plot([0,1], [0,1],  c='k', alpha=0.2);\n",
        "  # plt.title('Persistence diagram dim='+str(dim))\n",
        "  # plt.close('All')\n",
        "  plt.legend();\n",
        "plt.savefig(path_out+name+'PH/PD_all.jpeg')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WnR0Wdz4Lzsv",
        "Fu7-heDjxLkw",
        "ZQKe-3jldPvC"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}